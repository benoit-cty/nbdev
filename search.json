[
  {
    "objectID": "clean.html",
    "href": "clean.html",
    "title": "clean",
    "section": "",
    "text": "To avoid pointless conflicts while working with jupyter notebooks (with different execution counts or cell metadata), it is recommended to clean the notebooks before committing anything (done automatically if you install the git hooks with nbdev_install_hooks). The following functions are used to do that."
  },
  {
    "objectID": "clean.html#trust",
    "href": "clean.html#trust",
    "title": "clean",
    "section": "Trust",
    "text": "Trust\n\n\nnbdev_trust\n\n nbdev_trust (fname:str=None, force_all:bool=False)\n\nTrust notebooks matching fname\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to trust\n\n\nforce_all\nbool\nFalse\nAlso trust notebooks that haven’t changed"
  },
  {
    "objectID": "clean.html#clean",
    "href": "clean.html#clean",
    "title": "clean",
    "section": "Clean",
    "text": "Clean\n\n\nclean_nb\n\n clean_nb (nb, clear_all=False, allowed_metadata_keys:list=None,\n           allowed_cell_metadata_keys:list=None, clean_ids=True)\n\nClean nb from superfluous metadata\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnb\n\n\nThe notebook to clean\n\n\nclear_all\nbool\nFalse\nRemove all cell metadata and cell outputs\n\n\nallowed_metadata_keys\nlist\nNone\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nlist\nNone\nPreserve the list of keys in cell level metadata\n\n\nclean_ids\nbool\nTrue\nRemove ids from plaintext reprs?\n\n\n\nThe test notebook has metadata in both the main metadata section and contains cell level metadata in the second cell:\n\ntest_nb = read_nb('../tests/metadata.ipynb')\n\nassert {'meta', 'jekyll', 'my_extra_key', 'my_removed_key'} <= test_nb.metadata.keys()\nassert {'meta', 'hide_input', 'my_extra_cell_key', 'my_removed_cell_key'} == test_nb.cells[1].metadata.keys()\n\nAfter cleaning the notebook, all extra metadata is removed, only some keys are allowed by default:\n\nclean_nb(test_nb)\n\nassert {'jekyll', 'kernelspec'} == test_nb.metadata.keys()\nassert {'hide_input'} == test_nb.cells[1].metadata.keys()\n\nWe can preserve some additional keys at the notebook or cell levels:\n\ntest_nb = read_nb('../tests/metadata.ipynb')\nclean_nb(test_nb, allowed_metadata_keys={'my_extra_key'}, allowed_cell_metadata_keys={'my_extra_cell_key'})\n\nassert {'jekyll', 'kernelspec', 'my_extra_key'} == test_nb.metadata.keys()\nassert {'hide_input', 'my_extra_cell_key'} == test_nb.cells[1].metadata.keys()\n\nPassing clear_all=True removes everything from the cell metadata:\n\ntest_nb = read_nb('../tests/metadata.ipynb')\nclean_nb(test_nb, clear_all=True)\n\nassert {'jekyll', 'kernelspec'} == test_nb.metadata.keys()\ntest_eq(test_nb.cells[1].metadata, {})\n\nPassing clean_ids=True removes ids from plaintext repr outputs, to avoid notebooks whose contents change on each run since they often lead to git merge conflicts. For example:\n<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FB4F8979690>\nbecomes:\n<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>\n\n\n\nprocess_write\n\n process_write (warn_msg, proc_nb, f_in, f_out=None, disp=False)\n\n\n\n\nnbdev_clean\n\n nbdev_clean (fname:str=None, clear_all:bool=False, disp:bool=False,\n              stdin:bool=False)\n\nClean all notebooks in fname to avoid merge conflicts\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to clean\n\n\nclear_all\nbool\nFalse\nClean all metadata and outputs\n\n\ndisp\nbool\nFalse\nPrint the cleaned outputs\n\n\nstdin\nbool\nFalse\nRead notebook from input stream\n\n\n\nBy default (fname left to None), all the notebooks in lib_folder are cleaned. You can opt in to fully clean the notebook by removing every bit of metadata and the cell outputs by passing clear_all=True.\nIf you want to keep some keys in the main notebook metadata you can set allowed_metadata_keys in settings.ini. Similarly for cell level metadata use: allowed_cell_metadata_keys. For example, to preserve both k1 and k2 at both the notebook and cell level adding the following in settings.ini:\n...\nallowed_metadata_keys = k1 k2\nallowed_cell_metadata_keys = k1 k2\n...\n\n\n\nclean_jupyter\n\n clean_jupyter (path, model, **kwargs)\n\nClean Jupyter model pre save to path\nThis cleans notebooks on-save to avoid unnecessary merge conflicts. The easiest way to install it for both Jupyter Notebook and Lab is by running nbdev_install_hooks. It works by implementing a pre_save_hook from Jupyter’s file save hook API."
  },
  {
    "objectID": "clean.html#hooks",
    "href": "clean.html#hooks",
    "title": "clean",
    "section": "Hooks",
    "text": "Hooks\n\n\nnbdev_install_hooks\n\n nbdev_install_hooks ()\n\nInstall Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nSee clean_jupyter and nbdev_merge for more about how each hook works."
  },
  {
    "objectID": "maker.html#variable-helpers",
    "href": "maker.html#variable-helpers",
    "title": "maker",
    "section": "Variable helpers",
    "text": "Variable helpers\nThese functions let us find and modify the definitions of variables in Python modules.\n\n\nfind_var\n\n find_var (lines, varname)\n\nFind the line numbers where varname is defined in lines\n\nt = '''a_=(1,\n  2,\n  3)\n\nb_=3'''\ntest_eq(find_var(t.splitlines(), 'a_'), (0,3))\ntest_eq(find_var(t.splitlines(), 'b_'), (4,5))\n\n\n\n\nread_var\n\n read_var (code, varname)\n\nEval and return the value of varname defined in code\n\ntest_eq(read_var(t, 'a_'), (1,2,3))\ntest_eq(read_var(t, 'b_'), 3)\n\n\n\n\nupdate_var\n\n update_var (varname, func, fn=None, code=None)\n\nUpdate the definition of varname in file fn, by calling func with the current definition\n\ng = exec_new(t)\ntest_eq((g['a_'],g['b_']), ((1,2,3),3))\nt2 = update_var('a_', lambda o:0, code=t)\nexec(t2, g)\ntest_eq((g['a_'],g['b_']), (0,3))\nt3 = update_var('b_', lambda o:0, code=t)\nexec(t3, g)\ntest_eq((g['a_'],g['b_']), ((1,2,3),0))\n\n\n\n\nModuleMaker\n\n ModuleMaker (dest, name, nb_path, is_new=True, parse=True)\n\nHelper class to create exported library from notebook source cells\nIn order to export a notebook, we need an way to create a Python file. ModuleMaker fills that role. Pass in the directory where you want to module created, the name of the module, the path of the notebook source, and set is_new to True if this is a new file being created (rather than an existing file being added to). The location of the saved module will be in fname. Finally, if the source in the notebooks should not be parsed by Python (such as partial class declarations in cells), parse should be set to False.\n\nNote: If doing so, then the __all__ generation will be turned off as well.\n\n\nmm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'01_export.ipynb', is_new=True)\nmm.fname\n\nPath('tmp/test/testing.py')\n\n\n\n\ndecor_id\n\n decor_id (d)\n\nid attr of decorator, regardless of whether called as function or bare\n\n\n\nretr_exports\n\n retr_exports (trees)\n\n\n\n\nModuleMaker.make_all\n\n ModuleMaker.make_all (cells)\n\nCreate __all__ with all exports in cells\n\n\n\nmake_code_cells\n\n make_code_cells (*ss)\n\nWe want to add an __all__ to the top of the exported module. This methods autogenerates it from all code in cells.\n\nnb = make_code_cells(\"from __future__ import print_function\", \"def a():...\", \"def b():...\",\n                      \"c=d=1\", \"_f=1\", \"_g=1\", \"_all_=['_g']\", \"@patch\\ndef h(self:ca):...\")\ntest_eq(set(mm.make_all(nb)), set(['a','b','c','d', '_g']))\n\n\n\n\nrelative_import\n\n relative_import (name, fname, level=0)\n\nConvert a module name to a name relative to fname\n\ntest_eq(relative_import('nbdev.core', \"xyz\"), 'nbdev.core')\ntest_eq(relative_import('nbdev.core', 'nbdev'), '.core')\n_p = Path('fastai')\ntest_eq(relative_import('fastai.core', _p/'vision'), '..core')\ntest_eq(relative_import('fastai.core', _p/'vision/transform'), '...core')\ntest_eq(relative_import('fastai.vision.transform', _p/'vision'), '.transform')\ntest_eq(relative_import('fastai.notebook.core', _p/'data'), '..notebook.core')\ntest_eq(relative_import('fastai.vision', _p/'vision'), '.')\ntest_eq(relative_import('fastai', _p), '.')\ntest_eq(relative_import('fastai', _p/'vision'), '..')\ntest_eq(relative_import('fastai', _p/'vision/transform'), '...')\n\n\n\n\nNbCell.import2relative\n\n NbCell.import2relative (cell:execnb.nbio.NbCell, libname)\n\n\n\n\nupdate_import\n\n update_import (source, tree, libname, f=<functionrelative_import>)\n\n\nss = \"from nbdev.export import *\\nfrom nbdev.a.b import *\"\ncell = make_code_cells([ss])[0]\ncell.import2relative('nbdev')\ntest_eq(cell.source, 'from .export import *\\nfrom .a.b import *')\n\ncell = make_code_cells([ss])[0]\ncell.import2relative('nbdev/a')\ntest_eq(cell.source, 'from ..export import *\\nfrom .b import *')\n\n\n\n\nModuleMaker.make\n\n ModuleMaker.make (cells, all_cells=None, lib_path=None)\n\nWrite module containing cells with __all__ generated from all_cells\n\ncells = make_code_cells(\"from __future__ import print_function\", \"#|export\\ndef a(): ...\", \"def b(): ...\")\nmm.make(cells, L([cells[1]]))\nshow_src(Path('tmp/test/testing.py').read_text())\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../01_export.ipynb.\n\n# %% ../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% auto 0\n__all__ = ['a']\n\n# %% ../01_export.ipynb 2\n#|export\ndef a(): ...\n\n# %% ../01_export.ipynb 3\ndef b(): ...\n\n\nPass all_cells=[] or parse=False if you don’t want any __all__ added.\nPassing parse=False is also handy for when writing broken up functions or classes that ast.parse might not like but still want it to be exported, such as having once cell with the contents of:\n#|export\nclass A:\nNote that by doing so we cannot properly generate a __all__, so we assume that it is unwanted.\n\nam = ModuleMaker(dest='tmp', name='test.testing_noall', nb_path=Path.cwd()/'01_export.ipynb', is_new=True, parse=False)\nam.fname\n\nPath('tmp/test/testing_noall.py')\n\n\n\ncells = make_code_cells(\"from __future__ import print_function\", \"#|export\\ndef a(): ...\", \"#|export\\nclass A:\")\nam.make(cells)\nshow_src(Path('tmp/test/testing_noall.py').read_text())\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../01_export.ipynb.\n\n# %% ../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% ../01_export.ipynb 1\n#|export\ndef a(): ...\n\n# %% ../01_export.ipynb 2\n#|export\nclass A:\n\n\nIf is_new=False then the additional definitions are added to the bottom, and any existing __all__ is updated with the newly-added symbols.\n\nc2 = make_code_cells(\"def c(): ...\", \"def d(): ...\")\nmm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'01_export.ipynb', is_new=False)\nmm.make(c2, c2)\n\n\nshow_src(Path('tmp/test/testing.py').read_text())\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../01_export.ipynb.\n\n# %% ../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% auto 0\n__all__ = ['a', 'c', 'd']\n\n# %% ../01_export.ipynb 2\n#|export\ndef a(): ...\n\n# %% ../01_export.ipynb 3\ndef b(): ...\n\n# %% ../01_export.ipynb 0\ndef c(): ...\n\n# %% ../01_export.ipynb 1\ndef d(): ...\n\n\n\ng = exec_import('.tmp.test.testing', '*')\nfor s in \"a c d\".split(): assert s in g, s\nassert 'b' not in g\nassert g['a']() is None\n\n\n\n\nbasic_export_nb2\n\n basic_export_nb2 (fname, name, dest=None)\n\nA basic exporter to bootstrap nbdev using ModuleMaker\n\npath = Path('../nbdev')\n(path/'read.py').unlink(missing_ok=True)\n(path/'maker.py').unlink(missing_ok=True)\n\nadd_init(path)\ncfg = get_config()\n\nbasic_export_nb2('01_read.ipynb', 'read')\nbasic_export_nb2('02_maker.ipynb', 'maker')\n\ng = exec_import('nbdev', 'maker')\nassert g['maker'].ModuleMaker\nassert 'ModuleMaker' in g['maker'].__all__"
  },
  {
    "objectID": "export.html",
    "href": "export.html",
    "title": "export",
    "section": "",
    "text": "ExportModuleProc\n\n ExportModuleProc ()\n\nA processor which exports code to a module\nSpecify dest where the module(s) will be exported to, and optionally a class to use to create the module (ModuleMaker, by default).\nExported cells are stored in a dict called modules, where the keys are the modules exported to. Those without an explicit module are stored in the '#' key, which will be exported to default_exp.\n\neverything_fn = '../tests/01_everything.ipynb'\n\nexp = ExportModuleProc()\nproc = NBProcessor(everything_fn, exp)\nproc.process()\ntest_eq(exp.default_exp, 'everything')\nassert 'print_function'  in exp.modules['#'][0].source\nassert 'h_n' in exp.in_all['some.thing'][0].source\n\n\n\nblack_format\n\n black_format (cell, force=False)\n\nFormat code with black\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncell\n\n\nA cell node\n\n\nforce\nbool\nFalse\nTurn black formatting on regardless of settings.ini\n\n\n\n\n_cell = read_nb('../tests/black.ipynb')['cells'][0]\nblack_format(_cell, force=True)\ntest_eq(_cell.source, 'j = [1, 2, 3]')\n\n\n\n\ncreate_modules\n\n create_modules (path, dest, procs=None, debug=False,\n                 mod_maker=<class'nbdev.maker.ModuleMaker'>)\n\nCreate module(s) from notebook\nLet’s check we can import a test file:\n\nshutil.rmtree('tmp', ignore_errors=True)\ncreate_modules('../tests/00_some.thing.ipynb', 'tmp')\n\ng = exec_new('import tmp.some.thing')\ntest_eq(g['tmp'].some.thing.__all__, ['a'])\ntest_eq(g['tmp'].some.thing.a, 1)\n\nWe’ll also check that our ‘everything’ file exports correctly:\n\ncreate_modules(everything_fn, 'tmp')\n\ng = exec_new('import tmp.everything; from tmp.everything import *')\n_alls = L(\"a b d e m n o p q\".split())\nfor s in _alls.map(\"{}_y\"): assert s in g, s\nfor s in \"c_y_nall _f_y_nall g_n h_n i_n j_n k_n l_n\".split(): assert s not in g, s\nfor s in _alls.map(\"{}_y\") + [\"c_y_nall\", \"_f_y_nall\"]: assert hasattr(g['tmp'].everything,s), s\n\nThat notebook should also export one extra function to tmp.some.thing:\n\ndel(sys.modules['tmp.some.thing']) # remove from module cache\ng = exec_new('import tmp.some.thing')\ntest_eq(g['tmp'].some.thing.__all__, ['a','h_n'])\ntest_eq(g['tmp'].some.thing.h_n(), None)\n\n\n\n\nnb_export\n\n nb_export (nbname, lib_path=None)\n\n\nPath('../nbdev/export.py').unlink(missing_ok=True)\nnb_export('04a_export.ipynb')\n\ng = exec_new('import nbdev.export')\nassert hasattr(g['nbdev'].export, 'nb_export')"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "test",
    "section": "",
    "text": "test_nb\n\n test_nb (fn, skip_flags=None, force_flags=None, do_print=False,\n          showerr=True, basepath=None)\n\nExecute tests in notebook in fn except those with skip_flags\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfn\n\n\nfile name of notebook to test\n\n\nskip_flags\nNoneType\nNone\nlist of flags marking cells to skip\n\n\nforce_flags\nNoneType\nNone\nlist of flags marking cells to always run\n\n\ndo_print\nbool\nFalse\nprint completion?\n\n\nshowerr\nbool\nTrue\nwarn errors?\n\n\nbasepath\nNoneType\nNone\npath to add to sys.path\n\n\n\ntest_nb can test a notebook, and skip over certain flags:\n\n_nb = Path('../tests/directives.ipynb')\nsuccess,duration = test_nb(_nb, skip_flags=['notest'])\nassert success\nduration\n\n0.02329087257385254\n\n\nIn that notebook the cell flagged notest raises an exception, which will be returned as a bool:\n\n_nb = Path('../tests/directives.ipynb')\nsuccess,duration = test_nb(_nb, showerr=False)\nassert not success\n\nSometimes you may wish to override one or more of the skip_flags, in which case you can use the argument force_flags which will remove the appropriate tag(s) from skip_flags. This is useful because skip_flags are meant to be set in the tst_flags field of settings.ini, whereas force_flags are usually passed in by the user.\n\n\n\nnbdev_test\n\n nbdev_test (fname:str=None, flags:str='', n_workers:int=None,\n             timing:bool=False, do_print:bool=False, pause:float=0.01,\n             symlinks:bool=False, recursive:bool=None, file_re:str=None,\n             folder_re:str=None, skip_file_glob:str=None,\n             skip_file_re:str='^[_.]', ignore_fname:str='.notest')\n\nTest in parallel notebooks matching fname, passing along flags\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to test\n\n\nflags\nstr\n\nSpace separated list of test flags to run that are normally ignored\n\n\nn_workers\nint\nNone\nNumber of workers\n\n\ntiming\nbool\nFalse\nTime each notebook to see which are slow\n\n\ndo_print\nbool\nFalse\nPrint start and end of each notebook\n\n\npause\nfloat\n0.01\nPause time (in seconds) between notebooks to avoid race conditions\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nrecursive\nbool\nNone\nInclude subfolders?\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n1\nSkip files matching regex\n\n\nignore_fname\nstr\n.notest\nFilename that will result in siblings being ignored\n\n\n\n\nnbdev_test(n_workers=0)\n\nSuccess.\n\n\nYou can even run nbdev_test in non nbdev projects, for example, you can test an individual notebook like so:\n\n!nbdev_test --fname ../tests/minimal.ipynb --do_print\n\nStarting /Users/jhoward/git/nbdev/nbs/../tests/minimal.ipynb\n- Completed /Users/jhoward/git/nbdev/nbs/../tests/minimal.ipynb\nSuccess.\n\n\nOr you can test an entire directory of notebooks filtered for only those that match a regular expression like so:\n\n!nbdev_test --fname ../tests --file_re '.*test.ipynb' --do_print\n\nStarting /Users/jhoward/git/nbdev/nbs/../tests/2020-02-20-test.ipynb\nStarting /Users/jhoward/git/nbdev/nbs/../tests/showdoc_test.ipynb\n- Completed /Users/jhoward/git/nbdev/nbs/../tests/showdoc_test.ipynb\nStarting /Users/jhoward/git/nbdev/nbs/../tests/docs_test.ipynb\n- Completed /Users/jhoward/git/nbdev/nbs/../tests/docs_test.ipynb\n- Completed /Users/jhoward/git/nbdev/nbs/../tests/2020-02-20-test.ipynb\nSuccess.\n\n\n\n\n\n\n\nFootnotes\n\n\n_.↩︎"
  },
  {
    "objectID": "cli.html",
    "href": "cli.html",
    "title": "cli",
    "section": "",
    "text": "nbdev_ghp_deploy\n\n nbdev_ghp_deploy ()\n\nDeploy docs in doc_path from settings.ini to GitHub Pages\n\n\n\nnbdev_sidebar\n\n nbdev_sidebar (path:str=None, symlinks:bool=False, file_glob:str=None,\n                file_re:str='\\\\.(?:ipynb|qmd|html)$', folder_re:str=None,\n                skip_file_glob:str=None, skip_file_re:str='^[_.]',\n                skip_folder_re:str='(?:^[_.]|^www$)', printit:bool=False,\n                force:bool=False, returnit:bool=False)\n\nCreate sidebar.yml\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n1\nSkip files matching regex\n\n\nskip_folder_re\nstr\n(?:[_.]|www$)\nSkip folders matching regex\n\n\nprintit\nbool\nFalse\nPrint YAML for debugging\n\n\nforce\nbool\nFalse\nCreate sidebar even if settings.ini custom_sidebar=False\n\n\nreturnit\nbool\nFalse\nReturn list of files found\n\n\n\n\n# nbdev_sidebar(printit=True, force=True)\n\n\n\n\nFilterDefaults\n\n FilterDefaults ()\n\nOverride FilterDefaults to change which notebook processors are used\n\n\nnbdev_filter\n\n nbdev_filter (nb_txt:str=None, fname:str=None)\n\nA notebook filter for Quarto\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnb_txt\nstr\nNone\nNotebook text (uses stdin if not provided)\n\n\nfname\nstr\nNone\nNotebook to read (uses nb_txt if not provided)\n\n\n\n\n\n\nnbdev_bump_version\n\n nbdev_bump_version (part:int=2, unbump:bool=False)\n\nIncrement version in settings.ini by one\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npart\nint\n2\nPart of version to bump\n\n\nunbump\nbool\nFalse\nReduce version instead of increasing it\n\n\n\n\n\n\nbump_version\n\n bump_version (version, part=2, unbump=False)\n\n\n\n\nupdate_version\n\n update_version ()\n\nAdd or update __version__ in the main __init__.py of the library\n\n\n\nextract_tgz\n\n extract_tgz (url, dest='.')\n\n\n\n\nprompt_user\n\n prompt_user (cfg, inferred)\n\nLet user input values not in cfg or inferred.\n\n\n\nrefresh_quarto_yml\n\n refresh_quarto_yml ()\n\nGenerate _quarto.yml from settings.ini.\n\n\n\nnbdev_new\n\n nbdev_new (lib_name:str=None)\n\nCreate a new project from the current git repo\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlib_name\nstr\nNone\nPackage name (default: inferred from repo name)\n\n\n\n\n\n\nQuarto\n\n\nnbdev_readme\n\n nbdev_readme (path:str=None, doc_path:str=None)\n\nRender README.md from index.ipynb\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\ndoc_path\nstr\nNone\nPath to output docs\n\n\n\n\n\n\nnbdev_quarto\n\n nbdev_quarto (path:str=None, doc_path:str=None, symlinks:bool=False,\n               file_re:str='\\\\.(?:ipynb|qmd|html)$', folder_re:str=None,\n               skip_file_glob:str=None, skip_file_re:str=None,\n               preview:bool=False)\n\nCreate Quarto docs and README.md\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\ndoc_path\nstr\nNone\nPath to output docs\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\npreview\nbool\nFalse\nPreview the site instead of building it\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\n_.↩︎"
  },
  {
    "objectID": "merge.html",
    "href": "merge.html",
    "title": "merge",
    "section": "",
    "text": "When working with jupyter notebooks (which are json files behind the scenes) and GitHub, it is very common that a merge conflict (that will add new lines in the notebook source file) will break some notebooks you are working on. This module defines the function fix_conflicts to fix those notebooks for you, and attempt to automatically merge standard conflicts. The remaining ones will be delimited by markdown cells like this:\n<<<<<< HEAD\n\n# local code here\n\n======\n\n# remote code here\n\n>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\nBelow is an example of broken notebook. The json format is broken by the lines automatically added by git. Such a file can’t be opened in jupyter notebook.\n\nbroken = Path('../tests/example.ipynb.broken')\ntst_nb = broken.read_text()\nprint(tst_nb)\n\n{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 6,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"3\"\n      ]\n     },\n     \"execution_count\": 6,\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n<<<<<<< HEAD\n    \"z=3\\n\",\n=======\n    \"z=2\\n\",\n>>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n    \"z\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 7,\n   \"execution_count\": 5,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"6\"\n      ]\n     },\n<<<<<<< HEAD\n     \"execution_count\": 7,\n=======\n     \"execution_count\": 5,\n>>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n    \"x=3\\n\",\n    \"y=3\\n\",\n    \"x+y\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n\n\n\nNote that in this example, the second conflict is easily solved: it just concerns the execution count of the second cell and can be solved by choosing either option without really impacting your notebook. This is the kind of conflict we will fix automatically. The first conflict is more complicated as it spans across two cells and there is a cell present in one version, not the other. Such a conflict (and generally the ones where the inputs of the cells change form one version to the other) aren’t automatically fixed, but we will return a proper json file where the annotations introduced by git will be placed in markdown cells."
  },
  {
    "objectID": "merge.html#creating-a-merged-notebook",
    "href": "merge.html#creating-a-merged-notebook",
    "title": "merge",
    "section": "Creating a merged notebook",
    "text": "Creating a merged notebook\nThe approach we use is to first “unpatch” the conflicted file, regenerating the two files it was originally created from. Then we redo the diff process, but using cells instead of text lines.\n\n\nunpatch\n\n unpatch (s:str)\n\nTakes a string with conflict markers and returns the two original files, and their branch names\nThe result of “unpatching” our conflicted test notebook is the two original notebooks it would have been created from. Each of these original notebooks will contain valid JSON:\n\na,b,branch1,branch2 = unpatch(tst_nb)\ndict2nb(loads(a))\n\n{ 'cells': [{'cell_type': 'code', 'execution_count': 6, 'metadata': {}, 'outputs': [{'data': {'text/plain': ['3']}, 'execution_count': 6, 'metadata': {}, 'output_type': 'execute_result'}], 'source': 'z=3\\nz', 'idx_': 0}, {'cell_type': 'code', 'execution_count': 5, 'metadata': {}, 'outputs': [{'data': {'text/plain': ['6']}, 'execution_count': 7, 'metadata': {}, 'output_type': 'execute_result'}], 'source': 'x=3\\ny=3\\nx+y', 'idx_': 1}, {'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': '', 'idx_': 2}],\n  'metadata': { 'kernelspec': { 'display_name': 'Python 3',\n                                'language': 'python',\n                                'name': 'python3'}},\n  'nbformat': 4,\n  'nbformat_minor': 2}\n\n\n\ndict2nb(loads(b))\n\n{ 'cells': [{'cell_type': 'code', 'execution_count': 6, 'metadata': {}, 'outputs': [{'data': {'text/plain': ['3']}, 'execution_count': 6, 'metadata': {}, 'output_type': 'execute_result'}], 'source': 'z=2\\nz', 'idx_': 0}, {'cell_type': 'code', 'execution_count': 5, 'metadata': {}, 'outputs': [{'data': {'text/plain': ['6']}, 'execution_count': 5, 'metadata': {}, 'output_type': 'execute_result'}], 'source': 'x=3\\ny=3\\nx+y', 'idx_': 1}, {'cell_type': 'code', 'execution_count': None, 'metadata': {}, 'outputs': [], 'source': '', 'idx_': 2}],\n  'metadata': { 'kernelspec': { 'display_name': 'Python 3',\n                                'language': 'python',\n                                'name': 'python3'}},\n  'nbformat': 4,\n  'nbformat_minor': 2}\n\n\n\nbranch1,branch2\n\n('HEAD', 'a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35')\n\n\nThis begins by optionally backing the notebook fname to fname.bak in case something goes wrong. Then it parses the broken json, solving conflicts in cells. Every conflict that only involves metadata or outputs of cells will be solved automatically by using the local (theirs==False) or the remote (theirs==True) branch. Otherwise, or for conflicts involving the inputs of cells, the json will be repaired by including the two version of the conflicted cell(s) with markdown cells indicating the conflicts. You will be able to open the notebook again and search for the conflicts (look for <<<<<<<) then fix them as you wish.\nA message will be printed indicating whether the notebook was fully merged or if conflicts remain.\n\nnbdev_fix(broken, outname='tmp.ipynb')\nchk = read_nb('tmp.ipynb')\ntest_eq(len(chk.cells), 7)\nos.unlink('tmp.ipynb')\n\nOne or more conflict remains in the notebook, please inspect manually."
  },
  {
    "objectID": "merge.html#git-merge-driver",
    "href": "merge.html#git-merge-driver",
    "title": "merge",
    "section": "Git merge driver",
    "text": "Git merge driver\n\n\nnbdev_merge\n\n nbdev_merge (base:str, ours:str, theirs:str, path:str)\n\nGit merge driver for notebooks\nThis implements a git merge driver for notebooks that automatically resolves conflicting metadata and outputs, and splits remaining conflicts as separate cells so that the notebook can be viewed and fixed in Jupyter. The easiest way to install it is by running nbdev_install_hooks.\nThis works by first running Git’s default merge driver, and then nbdev_fix if there are still conflicts. You can set nbdev_fix’s theirs argument using the THEIRS environment variable, for example:\nTHEIRS=True git merge branch"
  },
  {
    "objectID": "process.html",
    "href": "process.html",
    "title": "process",
    "section": "",
    "text": "minimal = read_nb('../tests/minimal.ipynb')\n\n\n\nnb_lang\n\n nb_lang (nb)\n\n\n\n\nfirst_code_ln\n\n first_code_ln (code_list, re_pattern=None, lang='python')\n\n\n_tst = \"\"\" \n#|default_exp\n #|export\n#|hide_input\nfoo\n\"\"\"\ntest_eq(first_code_ln(_tst.splitlines(True)), 4)\n\n\n\n\nextract_directives\n\n extract_directives (cell, remove=True, lang='python')\n\nTake leading comment directives from lines of code in ss, remove #|, and split\nComment directives start with #|, followed by whitespace delimited tokens, which extract_directives extracts from the start of a cell, up until a blank line or a line containing something other than comments. The extracted lines are removed from the source.\n\nexp  = AttrDict(source = \"\"\"#|export module\n#|eval:false\n#| hide\n# | foo bar\n# |woo: baz\n1+2\n#bar\"\"\")\ntest_eq(extract_directives(exp), {'export':['module'], 'hide':[], 'eval:': ['false'], 'foo': ['bar'], 'woo:': ['baz']})\ntest_eq(exp.source, '#|eval: false\\n# |woo: baz\\n1+2\\n#bar')\n\n\n\n\nopt_set\n\n opt_set (var, newval)\n\nnewval if newval else var\n\n\n\ninstantiate\n\n instantiate (x, **kwargs)\n\nInstantiate x if it’s a type\n\n\n\nNBProcessor\n\n NBProcessor (path=None, procs=None, preprocs=None, postprocs=None,\n              nb=None, debug=False, rm_directives=True, process=False)\n\nProcess cells and nbdev comments in a notebook\nCell processors can be callables (e.g regular functions), in which case they are called for every cell:\n\neverything_fn = '../tests/01_everything.ipynb'\n\ndef print_execs(cell):\n    if 'exec' in cell.source: print(cell.source)\n\nNBProcessor(everything_fn, print_execs).process()\n\nexec(\"o_y=1\")\nexec(\"p_y=1\")\n_all_ = [o_y, 'p_y']\n\n\nComment directives are put in a cell attribute directive_ as a dictionary keyed by directive name:\n\ndef printme_func(cell):\n    if cell.directives_ and 'printme' in cell.directives_: print(cell.directives_['printme'])\n\nNBProcessor(everything_fn, printme_func).process()\n\n['testing']\n\n\nHowever, a more convenient way to handle comment directives is to use a class as a processor, and include a method in your class with the same name as your directive, surrounded by underscores:\n\nclass _PrintExample:\n    def _printme_(self, nbp, cell, to_print): print(to_print)\n\nNBProcessor(everything_fn, _PrintExample()).process()\n\ntesting\n\n\nIn the case that your processor supports just one comment directive, you can just use a regular function, with the same name as your directive, but with an underscore appended – here printme_ is identical to _PrintExample above:\n\ndef printme_(nbp, cell, to_print): print(to_print)\n\nNBProcessor(everything_fn, printme_).process()\n\ntesting\n\n\n\nbasic_export_nb2('01_read.ipynb', 'read')\nbasic_export_nb2('02_maker.ipynb', 'maker')\nbasic_export_nb2('03_process.ipynb', 'process')\n\ng = exec_new('import nbdev.process')\nassert hasattr(g['nbdev'].process, 'NBProcessor')"
  },
  {
    "objectID": "migrating.html",
    "href": "migrating.html",
    "title": "nbdev1 migration",
    "section": "",
    "text": "nbdev v2 is a new from-scratch rewrite of nbdev that’s not backwards compatible. This page describes the changes you need to make to upgrade your nbdev v1 repo to work with the new version. The steps shown here should work on macOS or Linux (including Windows WSL)\nThe biggest change is that nbdev2 uses Quarto to generate your website, whereas nbdev1 used nbconvert and jekyll. You can use all of Quarto’s features directly in nbdev, so checkout the Quarto website to see all the amazing functionality it supports."
  },
  {
    "objectID": "migrating.html#initial-setup",
    "href": "migrating.html#initial-setup",
    "title": "nbdev1 migration",
    "section": "Initial setup",
    "text": "Initial setup\nIf you’ve pinned nbdev in requirements.txt or settings.ini (e.g nbdev<2) remove the version pin. (If you don’t know what this means, then you don’t have it, so you can ignore this step).\nInstall the latest version of nbdev by typing:\npip install -U nbdev\nor:\nconda install -c fastai nbdev\nYou may need to restart your terminal for the new commands to be visible to your shell."
  },
  {
    "objectID": "migrating.html#upgrade-directives",
    "href": "migrating.html#upgrade-directives",
    "title": "nbdev1 migration",
    "section": "Upgrade directives",
    "text": "Upgrade directives\nnbdev has slightly changed how “directive comments” like export and default_exp work, in order to align with how Quarto does things. Now, instead of just adding a # to the start to indicate a directive (e.g #export), you now need to use #| (e.g #|export). You can also optionally add a space (e.g #| export).\nTo automatically upgrade your directives to the new format, run in the root of your repo:\nnbdev_migrate\nYou should now test that you can export your module by running:\nnbdev_export\nNote that nbdev_export replaces nbdev_build_lib. Run nbdev_export -h to see the options you can pass to it (normally you won’t need to pass any). To see a list of all the commands available in nbdev2, run nbdev_help."
  },
  {
    "objectID": "migrating.html#add-and-remove-files",
    "href": "migrating.html#add-and-remove-files",
    "title": "nbdev1 migration",
    "section": "Add and remove files",
    "text": "Add and remove files\nFirst set a variable with the name of your library, by running the following (replacing “yourlib” with the name of your library’s subdirectory)\nexport LIBNAME=yourlib\nNow run the following:\ngit rm Makefile\ngit add $LIBNAME/_modidx.py\nrm -rf docs\nrm -f .gitconfig \nrm -f .git/hooks/post-merge\n\nrm -f setup.py\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/styles.css\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/setup.py\n\ncat >>.gitignore <<EOF\n_docs/\nsidebar.yml\nEOF\nAs you see above, we’ve remove the Makefile – that’s because all the things done by make before are now handled by nbdev commands directly.\n\n\n\n\n\n\nNote\n\n\n\nAll documentation related files should be included in your nbs_path, and all paths should be relative to it. If you have set the nbs_path in your settings.ini file, then copy your styles.css file inside of your nbs_path folder.\n\n\nIf you use GitHub Actions for continuous integration (CI) you can update this to use nbdev too as follows:\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/.github/workflows/test.yaml\nmv test.yaml .github/workflows/"
  },
  {
    "objectID": "migrating.html#update-directive-names",
    "href": "migrating.html#update-directive-names",
    "title": "nbdev1 migration",
    "section": "Update directive names",
    "text": "Update directive names\nA number of directives have changed names. We’ll use perl to fix them. Run these lines in the root of your repo:\n[[ $SHELL = *bash ]] && shopt -s globstar\n\nperl -pi -e 's/#\\|\\s*hide_input/#| echo: false/' **/*.ipynb\nperl -pi -e 's/#\\|\\s*hide_output/#| output: false/' **/*.ipynb\nperl -pi -e 's/#\\|\\s*skip/#| eval: false/' **/*.ipynb\nperl -pi -e 's/from nbdev.export import notebook2script/from nbdev import nbdev_export/' **/*.ipynb\nperl -pi -e 's/notebook2script/nbdev_export/' **/*.ipynb\nperl -pi -e 's/#\\|?\\s*all_slow/#| nbflags skip_exec/' **/*.ipynb\nThese change the following directives to use functionality built into Quarto:\n\nhide_input –> echo: false\nhide_output –> output: false\nskip –> eval: false\n\nThey also update the new location and name of the nbdev_export python function, and use the new nbflags functionality if you have any notebooks that you’ve asked nbdev1 to skip (using all_slow)."
  },
  {
    "objectID": "migrating.html#final-steps",
    "href": "migrating.html#final-steps",
    "title": "nbdev1 migration",
    "section": "Final steps",
    "text": "Final steps\nYou should now edit settings.ini, and change doc_path from docs to _docs, since that’s where nbdev2 will build your website.\nIf you use a custom domain for your website, you should move your CNAME file into the directory containing your notebooks.\nBefore pushing to GitHub, check that your website looks OK locally by running:\nnbdev_preview\nNow prepare to commit to GitHub:\nnbdev_prepare\nYou can now commit to GitHub as usual. Finally, update Github Pages by clicking on the Settings tab in your repo, then click Pages on the left side bar. Set “Source” to gh-pages branch and the /root folder."
  },
  {
    "objectID": "migrate.html",
    "href": "migrate.html",
    "title": "migrate",
    "section": "",
    "text": "migrate_nb_fm (path, overwrite=True)\n\nMigrate fastpages front matter in notebooks to a raw cell.\n\n_nb = migrate_nb_fm('../tests/2020-09-01-fastcore.ipynb', overwrite=False)\nprint(_get_raw_fm(_nb))\n\n---\naliases:\n- /fastcore/\nauthor: <a href='https://twitter.com/HamelHusain'>Hamel Husain</a>\ncategories:\n- fastcore\n- fastai\ncomments: true\ndescription: A unique python library that extends the python programming language\n  and provides utilities that enhance productivity.\nimage: images/copied_from_nb/fastcore_imgs/td.png\ntitle: 'fastcore: An Underrated Python Library'\n\n---\n\n\n\n_nb = migrate_nb_fm('../tests/2020-02-20-test.ipynb', overwrite=False)\nprint(_get_raw_fm(_nb))\n\n---\naliases:\n- /jupyter/2020/02/20/test\ncategories:\n- jupyter\ncomments: true\ndescription: A tutorial of fastpages for Jupyter notebooks.\nimage: images/chart-preview.png\ntitle: Fastpages Notebook Blog Post\n\n---\n\n\n\n\n\n\n\n\n\n\n migrate_md_fm (path, overwrite=True)\n\nMake fastpages front matter in markdown files quarto compliant.\nHere is what the front matter of a markdown post looks like before:\n\nprint(run('head -n13 ../tests/2020-01-14-test-markdown-post.md'))\n\n---\ntoc: true\nlayout: post\ndescription: A minimal example of using markdown with fastpages.\ncategories: [markdown]\ntitle: An Example Markdown Post\n---\n# Example Markdown Post\n\n## Basic setup\n\nJekyll requires blog post files to be named according to the following format:\n\n\nAnd this is what it looks like after:\n\n_res = migrate_md_fm('../tests/2020-01-14-test-markdown-post.md', overwrite=False)\nprint(_res[:300])\n\n---\naliases:\n- /markdown/2020/01/14/test-markdown-post\ncategories:\n- markdown\ndescription: A minimal example of using markdown with fastpages.\ntitle: An Example Markdown Post\n\n---\n# Example Markdown Post\n\n## Basic setup\n\nJekyll requires blog post files to be named according to the following format:"
  },
  {
    "objectID": "migrate.html#convert-nbdev-v1-projects-to-nbdev-v2",
    "href": "migrate.html#convert-nbdev-v1-projects-to-nbdev-v2",
    "title": "migrate",
    "section": "Convert nbdev v1 projects to nbdev v2",
    "text": "Convert nbdev v1 projects to nbdev v2\n\nDirectives\nnbdev v2 directives start with a #| whereas v1 directives were comments without a pipe |.\n\n\n_repl_directives\n\n _repl_directives (code_str)\n\nfor example, if any of the lines below are valid nbdev v1 directives, they replaced with a #|:"
  },
  {
    "objectID": "migrate.html#callouts",
    "href": "migrate.html#callouts",
    "title": "migrate",
    "section": "Callouts",
    "text": "Callouts\nIn fastpages, there was a markdown shortuct for callouts for Note, Tip, Important and Warning with block quotes. Since Quarto has its own callout blocks with markdown syntax, we do not implement these shortcuts in nbdev. Instead, we offer a manual conversion utility for these callouts so that you can migrate from fastpages to Quarto.\n\n\n_convert_callout\n\n _convert_callout (s)\n\nConvert nbdev v1 to v2 callouts.\nFor example, the below markdown:\n\n_callouts=\"\"\"\n## Boxes / Callouts\n\n> Warning: There will be no second warning!\n\nOther text\n\n> Important: Pay attention! It's important.\n\n> Tip: This is my tip.\n\n> Note: Take note of `this.`\n\"\"\"\n\nGets converted to:\n\n\n\n## Boxes / Callouts\n\n:::{.callout-warning}\n\nThere will be no second warning!\n\n:::\n\nOther text\n\n:::{.callout-important}\n\nPay attention! It's important.\n\n:::\n\n\n\n\n\nnbdev_migrate\n\n nbdev_migrate (fname:str=None, disp:bool=False, stdin:bool=False,\n                no_skip:bool=False)\n\nConvert all directives and callouts in fname from v1 to v2\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to migrate\n\n\ndisp\nbool\nFalse\nPrint the outputs with newly formatted directives\n\n\nstdin\nbool\nFalse\nRead notebook from input stream\n\n\nno_skip\nbool\nFalse\nDo not skip directories beginning with an underscore"
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Tutorial",
    "section": "",
    "text": "This tutorial shows you how to create a Python package from scratch using nbdev.\nAlternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step:"
  },
  {
    "objectID": "tutorial.html#installation",
    "href": "tutorial.html#installation",
    "title": "Tutorial",
    "section": "Installation",
    "text": "Installation\nYou’ll need the following software to complete the tutorial, read on for specific installation instructions:\n\nPython\nA Python package manager: we recommend conda or pip\nJupyter Notebook\nnbdev\nQuarto\n\nIf you haven’t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager.\n\nInstall Jupyter Notebook\nLaunch a terminal and install Jupyter Notebook by entering:\nconda install notebook\n…or\npip install notebook\n…if you’re using the pip package manager.\nEnter y (for yes) if prompted. Installation should take a few seconds, during which text will be printed in the terminal. You’ll know its completed when you see the terminal prompt and are able to type again.\nYou can now launch Jupyter by entering:\njupyter notebook\nThis should open the Jupyter home page in a new browser tab:\n\n\n\n\n\n\n\n\n\n\n\nWhy not Jupyter Lab?\n\n\n\n\n\nAs Jupyter power users we still prefer Jupyter Notebook (with customizations) over more feature-full alternatives like Jupyter Lab, VSCode, or PyCharm. We find Jupyter Notebook simpler, faster, and more robust.\n\n\n\n\n\nInstall nbdev\nThe next step is to install nbdev itself. Jupyter Notebook comes with its own terminal, so we’ll use that moving forward.\nIn the Jupyter home page (shown in the previous section), click the “New” dropdown on the right side, then “Terminal”.\nA browser tab should open with a blank terminal:\n\n\n\n\n\nEnter:\nconda install -c fastai nbdev\n…or\npip install nbdev\n…if you’re using pip.\nType y (for yes) when prompted, and wait a few seconds until nbdev is installed.\n\n\nInstall Quarto\nnbdev provides a command to install the latest version of Quarto. In the terminal, enter:\nnbdev_install_quarto\nYour password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn’t doing anything malicious. Or, if you prefer, you may instead follow Quarto’s official installation instructions."
  },
  {
    "objectID": "tutorial.html#first-steps",
    "href": "tutorial.html#first-steps",
    "title": "Tutorial",
    "section": "First steps",
    "text": "First steps\nBy the end of this section you’ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website.\n\nCreate an empty GitHub repo\nCreate an empty GitHub repo using the convenient link github.com/new. If you get stuck, you might find GitHub’s Create a repo page helpful.\nRemember to add a description, since nbdev will use that later. Don’t add a README file, .gitignore, or license file just yet.\nIf you’re using the web interface, it should look something like this before you click “Create Repository”:\n\n\n\n\n\nYou should then be redirected to your new repo:\n\n\n\n\n\n\n\n\n\n\n\nTry GitHub’s powerful CLI\n\n\n\n\n\nGitHub’s web interface is a great way to get started. As you grow more experienced, you might want to explore the CLI (command line interface). We often prefer to use command line tools for repetitive tasks where we’re likely to make mistakes. Having those tasks written as small scripts in your terminal means that you can repeat them with little effort.\n\n\n\n\n\nInitialise your repo with nbdev\nNow clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub’s Cloning a repository page helpful.\nSince we created a repo named nbev-hello-world with the fastai user, we can clone it as follows:\ngit clone https://github.com/fastai/nbdev-hello-world.git\nThen cd (change directory) to our repo:\ncd nbdev-hello-world\nYou may have seen this message while cloning:\nYou appear to have cloned an empty repository.\n…since the repo is completely empty. Let’s add some files!\nnbdev provides the nbdev_new command to initialise an empty git repository. It’ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that:\n\nStreamline publishing Python packages to PyPI and conda\nConfigure Quarto for publication-grade technical documentation\nSetup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages\n\nInitialise your nbdev repo by entering:\nnbdev_new\nCommit and push all changes to GitHub:\ngit add .\ngit commit -m'Initial commit'\ngit push\nIt’s time to see all of the goodies nbdev gives you!\n\n\nCheck out your workflows\nOpen GitHub Actions by clicking the “Actions” tab near the top of your repo page. You should see two workflow runs:\n\n\n\n\n\nIf you opened this page shortly after pushing your initial commit, the runs may not have a green tick because they’re still “In progress” or “Queued”. That’s no problem, they shouldn’t take much more than a minute to complete.\nWhat do these mean?\n\nCI – The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that:\n\nYour notebooks and libraries are in sync\nYour notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts)\nYour notebook tests all pass\n\nDeploy to GitHub Pages – Builds your docs with Quarto and deploys it to GitHub Pages.\n\nNote that you’ll need to enable GitHub Pages for your repo before you can access your docs website. We’ll do that now.\n\n\nCheck out your docs\nnbdev hosts your docs on GitHub Pages—an excellent (and free!) way to host websites.\nYou can enable it for your repo by clicking on the “Settings” tab near the top-right of your repo page, then “Pages” on the left, then setting the “Branch” to “gh-pages”, and finally clicking “Save”.\n\n\n\n\n\n\nNote\n\n\n\nnbdev uses GitHub Pages by default because its easily accessible, however you can use any host you like.\n\n\nIt should look similar to this after you click “Save”:\n\n\n\n\n\nHead back to GitHub Actions and you should see a new workflow run: “pages build and deployment”. As the name says, this workflow deploys your website contents to GitHub Pages.\n\n\n\n\n\nWait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo}. For example, you can view fastai’s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world."
  },
  {
    "objectID": "tutorial.html#make-your-first-edit",
    "href": "tutorial.html#make-your-first-edit",
    "title": "Tutorial",
    "section": "Make your first edit",
    "text": "Make your first edit\n\nEdit settings.ini\nNext, edit the settings.ini file in your cloned repo. This file contains all the necessary information for when you’ll be ready to package your library. The basic structure (that can be personalized provided you change the relevant information in settings.ini) is that the root of the repo will contain your notebooks, the docs folder will contain your auto-generated docs, and a folder with a name you select will contain your auto-generated modules.\n\n\nBuild and install lib\nNow you can create your Python module. To do so, just run nbdev_export from the terminal at the root of your project folder, which builds the .py modules and library from the jupyter notebook.\nBefore you continue, you should ensure you have the latest version of your Python library and Quarto installed. Run nbdev_install to do an editable install of your local Python library as well as fetch and install the latest version of Quarto.\n\n\nInstall git and Jupyter hooks for git-friendly notebooks\nJupyter Notebooks store additional metadata (like cell execution order) which cause challenges with git. nbdev makes working with notebooks becomes much easier. As a first step, run nbdev_install_hooks in the terminal from your project folder. This sets up a jupyter hook which remove metadata from your notebooks automatically, avoiding unnecessary file changes and greatly reducing the chance of a conflict. It also installs a git hook which attempts to resolve conflicts, and if any conflicts can’t be resolved, places conflict markers into a notebook which you can fix directly in Jupyter.\n\n\nStart the Documentation Server\nYou can call nbdev_preview from the root of the repo to start the documentation server so you can see how your docs will render as you edit your notebooks. This is optional, but often useful especially if you are writing docs.\n\n\nEdit 00_core.ipynb\nNow, run jupyter notebook, and click 00_core.ipynb (you don’t have to start your notebook names with a number like we do here; but we find it helpful to show the order you’ve created your project in). You’ll see something that looks a bit like this:\n#|default_exp core\nmodule name here\n\nAPI details.\n\nLet’s explain what these special cells mean.\n\nModule name and summary\nThe markdown cell uses special syntax to define the title and summary of your module. Feel free to replace “module name here” with a title and “API details.” with a summary for your module.\n\n\nAdd a function\nLet’s add a function to this notebook, e.g.:\n#|export\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nNotice how it includes #|export at the top - this means it will be included in your module, and documentation. The documentation will look like this:\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\n\nAdd examples and tests\nIt’s a good idea to give an example of your function in action. Just include regular code cells, and they’ll appear (with output) in the docs, e.g.:\n\nsay_hello(\"Isaac\")\n\n'Hello Isaac!'\n\n\nExamples can output plots, images, etc, and they’ll all appear in your docs, e.g.:\n\nfrom IPython.display import display,SVG\n\n\ndisplay(SVG('<svg height=\"100\"><circle cx=\"50\" cy=\"50\" r=\"40\"/></svg>'))\n\n\n\n\nYou can also include tests:\n\nassert say_hello(\"Hamel\")==\"Hello Hamel!\"\n\nYou should also add markdown headings as you create your notebook; one benefit of this is that a table of contents will be created in the documentation automatically.\n\n\n\nEdit index.ipynb\nNow you’re ready to create your documentation home page and README.md file; these are both generated automatically from index.ipynb. So click on that to open it now.\nYou’ll see that there’s already a line there to import your library - change it to use the name you selected in settings.ini. Then, add information about how to use your module, including some examples. Remember, these examples should be actual notebook code cells with real outputs.\n\n\nPreview the docs\nIf you have not already, you should view your docs in fully rendered form to catch any mistakes. You can preview your documentation site with the command nbdev_preview. Note that your docs will build automatically in CI (discussed below).\n\n\nCommit to Github\nBefore commiting to GitHub we recommend running nbdev_prepare, which bundles the following commands together for you to test your code and build the library:\n\nnbdev_export: Builds the .py modules and library from the jupyter notebook\nnbdev_test: Tests all your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for Github\n\nYou can now check-in the generated files with git add, git commit and git push. (You can use git status to check which files have been generated.) The following command should be sufficient:\ngit add -A; git commit -m'check in files'; git push\nWait a minute or two for Github to process your commit, and then head over to the Github website to look at your results.\n\n\nContinuous Integration (CI)\nBack in your project’s Github main page, click where it says 1 commit (or 2 commits or whatever). Hopefully, you’ll see a green checkmark next to your latest commit. That means that your documentation site built correctly, and your module’s tests all passed! This is checked for you using continuous integration (CI) with GitHub actions. This does the following:\n\ncheck the notebooks have been cleaned of needless metadata to avoid merge conflicts (with nbdev_clean)\nrun the tests in your notebooks (with nbdev_test)\n\nThe template contains a basic CI that uses the two points above, edit the file .github/workflows/test.yaml to your liking and comment out the parts you don’t want.\nIf you have a red cross, that means something failed. Click on the cross, then click Details, and you’ll be able to see what failed.\n\nAutomatically building Docs\nCI will automatically build docs and deploy them for you. You can see the code for this in .github/workflows/deploy.yaml. You can enable Github Pages by clicking on the Settings tab in your repo, then click Pages on the left side bar. Set “Source” to gh-pages branch and the /root folder. Once you’ve saved, if you refresh that page, Github will have a link to your new website. Copy that URL, and then go back to your main repo page, click “edit” next to the description and paste the URL into the “website” section. While you’re there, go ahead and put in your project description too.\n\n\nDocs URL\nTo see the URL for your docs site, you can go to the Settings tab on your GitHub repo, click Pages on the left hand side, and your URL will be displayed there. If you need to customize the domain name, see this article.\n\n\n\nView docs and readme\nOnce everything is passing, have a look at your readme in Github. You’ll see that your index.ipynb file has been converted to a readme automatically.\nNext, go to your documentation site (e.g. by clicking on the link next to the description that you created earlier). You should see that your index notebook has also been used here.\nCongratulations, the basics are now all in place! Let’s continue and use some more advanced functionality."
  },
  {
    "objectID": "tutorial.html#advanced-functionality",
    "href": "tutorial.html#advanced-functionality",
    "title": "Tutorial",
    "section": "Advanced functionality",
    "text": "Advanced functionality\n\nAdd a class\nCreate a class in 00_core.ipynb as follows:\n#|export\nclass HelloSayer:\n    \"Say hello to `to` using `say_hello`\"\n    def __init__(self, to): self.to = to\n        \n    def say(self):\n        \"Do the saying\"\n        return say_hello(self.to)\nThis will automatically appear in the docs like this:\n\n\n\nHelloSayer\n\n HelloSayer (to)\n\nSay hello to to using say_hello\n\nDocument with show_doc\nHowever, methods aren’t automatically documented. To add method docs, use show_doc:\nshow_doc(HelloSayer.say)\n\n\n\nHelloSayer.say\n\n HelloSayer.say ()\n\nDo the saying\nAnd add some examples and/or tests:\n\no = HelloSayer(\"Alexis\")\no.say()\n\n'Hello Alexis!'\n\n\n\n\n\nAdd links with backticks\nNotice above there is a link from our new class documentation to our function. That’s because we used backticks in the docstring:\n    \"Say hello to `to` using `say_hello`\"\nThese are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks.\n\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2\n\n\nAdd in-notebook export cell\nIt’s helpful to be able to export all your modules directly from a notebook, rather than going to the terminal to do it. All nbdev commands are available directly from a notebook in Python. A new cell with the following contents and run it to export your modules (I normally make this the last cell of my notebooks).\n#| hide\nfrom nbdev import nbdev_export\nnbdev_export()\n\n\nCode Execution & Skipping Cells\nIf you want to prevent code from getting executed when rendering or testing docs, use the comment #|eval: false in a code cell.\nSee the Quarto docs for more execution options.\n\n\nSet up prerequisites\nIf your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too.\nFor example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib, then the prerequisites would look like this:\nrequirements = fastcore>=1.0.5 torchvision<0.7 matplotlib\nIn addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords:\n\nrequirements: Passed to both pip and conda setup\npip_requirements: Passed to pip setup only\nconda_requirements: Passed to conda setup only\ndev_requirements: Passed to pip setup as a development requirement\n\nFor more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml, respectively.\n\n\nSet up console scripts\nBehind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts. nbdev surfaces this functionality; to use it, use the same format as setuptools, with whitespace between each script definition (if you have more than one).\nconsole_scripts = nbdev_export=nbdev.cli:nbdev_export\n\n\nUpload to pypi\nIf you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi. The good news is, we’ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click “Register” on pypi) if you haven’t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents:\n[pypi]\nusername = your_pypi_username\npassword = your_pypi_password\nAnother thing you will need is twine, so you should run once\npip install twine\nTo upload your project to pypi, just type nbdev_pypi in your project root directory. Once it’s complete, a link to\n\n\nUpload to pypi and conda\nThe command nbdev_release from the root of your nbdev repo will bump the version of your module and upload your project to both conda and pypi.\n\n\nInstall collapsible headings and toc2\nThere are two jupyter notebook extensions that I highly recommend when working with projects like this. They are:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings.\n\n\n\nMath equation support\nnbdev supports equations (using Quarto). You can include math in your notebook’s documentation using the following methods.\nUsing $$, e.g.:\n\n$$\\sum_{i=1}^{k+1}i$$\n\nWhich is rendered as:\n\n\\[\\sum_{i=1}^{k+1}i\\]\n\nUsing $, e.g.:\nThis version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after.\nWhich is rendered as:\n\nThis version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after.\n\nFor more information, see the Quarto Docs\n\n\nControling Cell and Output Visibility\nTo control what is displayed or hidden in the docs from a notebook, you will want to use one more directives. Directives are special comments that have are preceeded by #| that do some kind of pre or post processing of a notebook data before docs are rendered. Some of these directives are part of Quarto, but others are ones that we have added to nbdev. A walk-through of the most common ones are below:\n\n#|hide\nWhen you use this directive, you will not see the cell input or output.\n\n\n#|echo: false\nThis makes sure that only the output of a code cell is shown, not its input.\n\n\nyou can see the output but not the code!\n\n\n\n\n#|hide_line\nYou can use this to hide as specific line in your code. for example:\ndef _secret(): ...\n\nfor i in range(3):\n    _secret() #|hide_line\n    print(i)\nbecomes this:\n\ndef _secret(): ...\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\n\n#|filter_stream\nThis allows you to filter lines containing specific keywords in cell outputs. For example\n\n#|filter_stream FutureWarning MultiIndex\nprint('\\n'.join(['A line', 'Foobar baz FutureWarning blah', \n                 'zig zagMultiIndex zoom', 'Another line.']))\nbecomes this:\n\nprint('\\n'.join(['A line', 'Foobar baz FutureWarning blah', \n                 'zig zagMultiIndex zoom', 'Another line.']))\n\nA line\nAnother line.\n\n\nSee the Quarto docs for additional code visibility options.\n\n\n\nCLI Command List\nYou can quickly pull up a list of all the nbdev cli commands as well as a short description of what each command does with the command nbdev_help.\n\n\nLook at nbdev “source” for more ideas\nDon’t forget that nbdev itself is written in nbdev! It’s a good place to look to see how fast.ai uses it in practice, and get a few tips. You’ll find the nbdev notebooks here in the nbs folder on Github."
  },
  {
    "objectID": "tutorial.html#quarto-features",
    "href": "tutorial.html#quarto-features",
    "title": "Tutorial",
    "section": "Quarto Features",
    "text": "Quarto Features\nnbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate mermaid charts:\n\n\n\n\nflowchart LR\n  A[Hard edge] --> B(Round edge)\n  B --> C{Decision}\n  C --> D[Result one]\n  C --> E[Result two]\n\n\n\n\n\n\n\n\nHere is another example of using Graphviz:\n\n\n\n\n\n\n\nG\n\n  \n\nrun\n\n run   \n\nintr\n\n intr   \n\nrun–intr\n\n   \n\nkernel\n\n kernel   \n\nrun–kernel\n\n   \n\nrunbl\n\n runbl   \n\nintr–runbl\n\n   \n\nrunbl–run\n\n   \n\nzombie\n\n zombie   \n\nkernel–zombie\n\n   \n\nsleep\n\n sleep   \n\nkernel–sleep\n\n   \n\nrunmem\n\n runmem   \n\nkernel–runmem\n\n   \n\nsleep–runmem\n\n   \n\nswap\n\n swap   \n\nsleep–swap\n\n   \n\nrunswap\n\n runswap   \n\nswap–runswap\n\n   \n\nrunswap–runmem\n\n   \n\nnew\n\n new   \n\nrunswap–new\n\n   \n\nnew–runmem\n\n  \n\n\n\n\n\nIt is worth taking a look at the documentation for figures, callouts, markdown, widgets, layouts, conditional content and quarto extensions to name a few useful things we have encountered."
  },
  {
    "objectID": "shortcuts.html",
    "href": "shortcuts.html",
    "title": "shortcuts",
    "section": "",
    "text": "install ()\n\nInstall Quarto and the current library\n\n\n\n\n\n install_quarto ()\n\nInstall latest Quarto on macOS or Linux, prints instructions for Windows"
  },
  {
    "objectID": "shortcuts.html#docs",
    "href": "shortcuts.html#docs",
    "title": "shortcuts",
    "section": "Docs",
    "text": "Docs\n\nGenerate Docs\n\n\ndocs\n\n docs (path:str=None, doc_path:str=None, symlinks:bool=False,\n       folder_re:str=None, skip_file_glob:str=None, skip_file_re:str=None,\n       preview:bool=False)\n\nGenerate docs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\ndoc_path\nstr\nNone\nPath to output docs\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\npreview\nbool\nFalse\nPreview the site instead of building it\n\n\n\n\n\n\nPreview Docs\n\n\npreview\n\n preview ()\n\nStart a local docs webserver\n\n\n\nDeploy Docs\n\n\ndeploy\n\n deploy ()\n\nDeploy docs to GitHub Pages"
  },
  {
    "objectID": "shortcuts.html#publish-packages",
    "href": "shortcuts.html#publish-packages",
    "title": "shortcuts",
    "section": "Publish Packages",
    "text": "Publish Packages\n\n\nrelease\n\n release ()\n\nRelease both conda and PyPI packages\n\n\n\nconda\n\n conda (ver_bump=True)\n\nCreate and upload a conda package\n\n\n\npypi\n\n pypi (ver_bump:bool=True, repository:str='pypi')\n\nCreate and upload Python package to PyPI\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nver_bump\nbool\nTrue\nBump version\n\n\nrepository\nstr\npypi\nRespository to upload pypi, testpypi or other location defined in ~/.pypirc"
  },
  {
    "objectID": "shortcuts.html#other-shortcuts",
    "href": "shortcuts.html#other-shortcuts",
    "title": "shortcuts",
    "section": "Other Shortcuts",
    "text": "Other Shortcuts\n\n\nprepare\n\n prepare ()\n\nExport, test, and clean notebooks"
  },
  {
    "objectID": "shortcuts.html#help",
    "href": "shortcuts.html#help",
    "title": "shortcuts",
    "section": "Help",
    "text": "Help\nGenerate help for all console scripts\n\n\nchelp\n\n chelp ()\n\nShow help for all console scripts\n\nchelp()\n\nnbdev_bump_version              Increment version in settings.ini by one\nnbdev_changelog                 Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean                     Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda                     Create and upload a conda package\nnbdev_create_config             Create a config file\nnbdev_deploy                    Deploy docs to GitHub Pages\nnbdev_docs                      Generate docs\nnbdev_export                    Export notebooks in `path` to Python modules\nnbdev_filter                    A notebook filter for Quarto\nnbdev_fix                       Create working notebook from conflicted notebook `nbname`\nnbdev_ghp_deploy                Deploy docs in `doc_path` from settings.ini to GitHub Pages\nnbdev_help                      Show help for all console scripts\nnbdev_install                   Install Quarto and the current library\nnbdev_install_hooks             Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto            Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge                     Git merge driver for notebooks\nnbdev_migrate                   Convert all directives and callouts in `fname` from v1 to v2\nnbdev_new                       Create a new project from the current git repo\nnbdev_prepare                   Export, test, and clean notebooks\nnbdev_preview                   Start a local docs webserver\nnbdev_pypi                      Create and upload Python package to PyPI\nnbdev_quarto                    Create Quarto docs and README.md\nnbdev_readme                    Render README.md from index.ipynb\nnbdev_release                   Release both conda and PyPI packages\nnbdev_release_gh                Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git               Tag and create a release in GitHub for the current version\nnbdev_sidebar                   Create sidebar.yml\nnbdev_test                      Test in parallel notebooks matching `fname`, passing along `flags`\nnbdev_trust                     Trust notebooks matching `fname`\nnbdev_update                    Propagate change in modules matching `fname` to notebooks that created them"
  },
  {
    "objectID": "read.html",
    "href": "read.html",
    "title": "read",
    "section": "",
    "text": "create_output (txt, mime)\n\nAdd a cell output containing txt of the mime text MIME sub-type\n\n\n\n\n\n show_src (src, lang='python')\n\n\nshow_src(\"print(create_output('text', 'text/plain'))\")\n\nprint(create_output('text', 'text/plain'))"
  },
  {
    "objectID": "read.html#config",
    "href": "read.html#config",
    "title": "read",
    "section": "Config",
    "text": "Config\nnbdev allows per-user and per-repo settings files in the ConfigParser format, conveniently read and written using fastcore’s Config class. Settings are searched in the following order:\n\nDefault settings: see nbdev_create_config for a full reference of possible settings and their defaults\nRepo settings: settings.ini file in the root of each project\nUser settings: settings.ini file following the XDG base directory specification, by default: ~/.config/nbdev/settings.ini\n\n\n\nnbdev_create_config\n\n nbdev_create_config (user:str, author:str, author_email:str,\n                      description:str, path:str='.',\n                      cfg_name:str='settings.ini', lib_name:str=None,\n                      branch='master',\n                      git_url='https://github.com/%(user)s/%(lib_name)s',\n                      custom_sidebar:<functionbool_arg>=False,\n                      nbs_path='.', lib_path='%(lib_name)s',\n                      doc_path='_docs', tst_flags='', version='0.0.1',\n                      doc_host='https://%(user)s.github.io',\n                      doc_baseurl='/%(lib_name)s',\n                      keywords='nbdevjupyternotebookpython',\n                      license='apache2', copyright:str=None, status='3',\n                      min_python='3.7', audience='Developers',\n                      language='English',\n                      recursive:<functionbool_arg>=False,\n                      black_formatting:<functionbool_arg>=False,\n                      readme_nb='index.ipynb', title='%(lib_name)s',\n                      allowed_metadata_keys='',\n                      allowed_cell_metadata_keys='', jupyter_hooks=True,\n                      clean_ids=True)\n\nCreate a config file\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nuser\nstr\n\nRepo username\n\n\nauthor\nstr\n\nPackage author’s name\n\n\nauthor_email\nstr\n\nPackage author’s email address\n\n\ndescription\nstr\n\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\nNone\nPackage name, defaults to local repo folder name passed to apply_defaults\n\n\nbranch\nstr\nmaster\nRepo default branch passed to apply_defaults\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(lib_name)s\nRepo URL passed to apply_defaults\n\n\ncustom_sidebar\nbool_arg\nFalse\nCreate custom sidebar? passed to apply_defaults\n\n\nnbs_path\nstr\n.\nPath to notebooks passed to apply_defaults\n\n\nlib_path\nstr\n%(lib_name)s\nPath to package root passed to apply_defaults\n\n\ndoc_path\nstr\n_docs\nPath to rendered docs passed to apply_defaults\n\n\ntst_flags\nstr\n\nTest flags passed to apply_defaults\n\n\nversion\nstr\n0.0.1\nVersion of this release passed to apply_defaults\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs passed to apply_defaults\n\n\ndoc_baseurl\nstr\n/%(lib_name)s\nBase URL for docs passed to apply_defaults\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords passed to apply_defaults\n\n\nlicense\nstr\napache2\nLicense for the package passed to apply_defaults\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’ passed to apply_defaults\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier passed to apply_defaults\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier passed to apply_defaults\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier passed to apply_defaults\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier passed to apply_defaults\n\n\nrecursive\nbool_arg\nFalse\nInclude subfolders in notebook globs? passed to apply_defaults\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black? passed to apply_defaults\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme passed to apply_defaults\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title passed to apply_defaults\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata passed to apply_defaults\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata passed to apply_defaults\n\n\njupyter_hooks\nbool\nTrue\nRun Jupyter hooks? passed to apply_defaults\n\n\nclean_ids\nbool\nTrue\nRemove ids from plaintext reprs? passed to apply_defaults\n\n\n\nThis is a wrapper for fastcore’s save_config_file with nbdev’s required settings. It is also installed as a CLI command. The table above also serves as a full reference of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved). For more about PyPI classifiers, see Classifiers.\n\ntest_eq(_nbdev_config_file(), Path.cwd().parent/'settings.ini')\n\n\n\n\nget_config\n\n get_config (cfg_name='settings.ini', path=None)\n\nConfig for ini file found in path (defaults to cwd)\nget_config searches for repo settings.ini in the current directory, and then in all parent directories, stopping when it is found. Default values for optional settings are applied to the resulting Config, see nbdev_create_config for a full reference of nbdev’s settings.\n\ncfg_name = 'test_settings.ini'\nnbdev_create_config('fastai','author','author@fast.ai','description','..',cfg_name)\ncfg = get_config(cfg_name)\ntest_eq(cfg.lib_name, 'nbdev')\ntest_eq(cfg.git_url, 'https://github.com/fastai/nbdev')\ncwd = Path.cwd()\ntest_eq(cfg.config_path, cwd.parent.absolute())\ntest_eq(cfg.path('lib_path'), cwd.parent/'nbdev')\ntest_eq(cfg.path('nbs_path'), cwd.parent)\ntest_eq(cfg.path('doc_path'), cwd.parent/'_docs')\ncfg.config_file.unlink()\nget_config.cache_clear()\n\n\n\nconfig_key\n\n config_key (c, default=None, path=True, missing_ok=None)\n\nLook for key c in settings.ini and fail gracefully if not found and no default provided"
  },
  {
    "objectID": "read.html#exporting-a-basic-module",
    "href": "read.html#exporting-a-basic-module",
    "title": "read",
    "section": "Exporting a basic module",
    "text": "Exporting a basic module\n\n\nadd_init\n\n add_init (path)\n\nAdd __init__.py in all subdirs of path containing python files if it’s not there already\nPython modules require a __init.py__ file in all directories that are modules. We assume that all directories containing a python file (including in subdirectories of any depth) is a module, and therefore add a __init__.py to each.\n\nwith tempfile.TemporaryDirectory() as d:\n    d = Path(d)\n    (d/'a/b').mkdir(parents=True)\n    (d/'a/b/f.py').touch()\n    (d/'a/c').mkdir()\n    add_init(d)\n    assert not (d/'a/c'/_init).exists(), \"Should not add init to dir without py file\"\n    for e in [d, d/'a', d/'a/b']: assert (e/_init).exists(),f\"Missing init in {e}\"\n\n\n\n\nwrite_cells\n\n write_cells (cells, hdr, file, offset=0)\n\nWrite cells to file along with header hdr starting at index offset (mainly for nbdev internal use)\n\n\n\nbasic_export_nb\n\n basic_export_nb (fname, name, dest=None)\n\nBasic exporter to bootstrap nbdev\nThis is a simple exporter with just enough functionality to correctly export this notebook, in order to bootstrap the creation of nbdev itself."
  },
  {
    "objectID": "doclinks.html",
    "href": "doclinks.html",
    "title": "doclinks",
    "section": "",
    "text": "DocLinks (mod_fn, doc_func, dest_fn, mod_name=None)\n\nCreate a module symbol index from a Python source file\nThe doc index has to be stored in a file. Usually we call it _modidx.py. For testing, we’ll delete any existing file first.\n\ndest_fn = Path('tmp/_modidx.py')\nwith contextlib.suppress(FileNotFoundError): dest_fn.unlink()\n\nA link to docs is created by a doc_func. We’ll use a dummy one for testing.\n\ndef _help(m, s=None): return f\"help for {m}; {s}\"\n\nWe’re now ready to instantiate DocLinks for our test module.\n\nmod_fn = Path('tmp/everything.py')\nlink = DocLinks(mod_fn, _help, dest_fn)\nlink.mod_name\n\n'tmp.everything'\n\n\n\n\n\n\n DocLinks.write_nbdev_idx ()\n\nCreate nbdev documentation index file`\nInitially the index file will contain empty syms and settings:\n\ntmp_path = Path('tmp')\ntmp_path.mkdir(exist_ok=True)\nlink.write_nbdev_idx()\nassert \"Autogenerated\" in dest_fn.read_text()\n\nprint(Path('tmp/_modidx.py').read_text())\n\n# Autogenerated by nbdev\n\nd = {'settings': {}, 'syms': {}}\n\n\n\n\n\n\n\n get_patch_name (o)\n\n\ns = \"\"\"class _T: pass\n@patch\ndef _f(self:_T): pass\n@patch_to(_T)\ndef _g(self): pass\"\"\"\n\nres = [get_patch_name(o) for o in ast.parse(s).body]\ntest_eq([None, '_T._f', '_T._g'], res)\n\n\n\n\n\n\n DocLinks.update_syms ()\n\nWe have a test notebook we can export to create a test python module:\n\neverything_fn = '../tests/01_everything.ipynb'\nnb_export('../tests/00_some.thing.ipynb', 'tmp')\nnb_export(everything_fn, 'tmp')\n\n\nlink.update_syms()\nlink.write_nbdev_idx()\n\n\ng = exec_new('import tmp._modidx')\nd = g['tmp']._modidx.d\nsymn = 'tmp.everything.a_y'\nmod_name = 'tmp.everything'\ntest_eq(d['syms'][mod_name][symn], _help(mod_name,symn))\ntest_eq(set(d['syms'][mod_name].keys()),\n        set(L('m_y', 'n_y', 'q_y', 'a_y', 'b_y', 'd_y', 'e_y', 'o_y', 'p_y', 'd_y.di_n', 'd_y.d3i_n', 'd_y.d4i_n'\n             ).map('tmp.everything.{}')))\n\n\n\n\n\n\n DocLinks.build_index ()\n\n\nlink.build_index()\ndel(sys.modules['tmp._modidx'])\ng = exec_new('import tmp._modidx')\nd = g['tmp']._modidx.d\ntest_eq(d['settings']['lib_name'], 'nbdev')\n\n\n\n\n\n\n build_modidx ()\n\nCreate _modidx.py\n\n\n\n\n\n nbglob (path=None, skip_folder_re='^[_.]', file_glob='*.ipynb',\n         recursive=True, key='nbs_path', as_path=False,\n         symlinks:bool=True, file_re:str=None, folder_re:str=None,\n         skip_file_glob:str=None, skip_file_re:str=None,\n         func:callable=<functionjoin>)\n\nFind all files in a directory matching an extension given a config_key.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nNoneType\nNone\npath to start searching passed to globtastic\n\n\nskip_folder_re\nstr\n1\nSkip folders matching regex, passed to globtastic\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob passed to globtastic\n\n\nrecursive\nbool\nTrue\nsearch subfolders passed to globtastic\n\n\nkey\nstr\nnbs_path\n\n\n\nas_path\nbool\nFalse\n\n\n\nsymlinks\nbool\nTrue\nfollow symlinks? passed to globtastic\n\n\nfile_re\nstr\nNone\nOnly include files matching regex passed to globtastic\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex passed to globtastic\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob passed to globtastic\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex passed to globtastic\n\n\nfunc\ncallable\njoin\nfunction to apply to each matched file passed to globtastic\n\n\n\n\n\n\n\n\n nbdev_export (path:str=None, recursive:bool=None, symlinks:bool=True,\n               file_re:str=None, folder_re:str=None,\n               skip_file_glob:str=None, skip_file_re:str='^[_.]')\n\nExport notebooks in path to Python modules\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath or filename\n\n\nrecursive\nbool\nNone\nSearch subfolders\n\n\nsymlinks\nbool\nTrue\nFollow symlinks?\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n2\nSkip files matching regex\n\n\n\n\n\n\n\n\n\n NbdevLookup (strip_libs=None, incl_libs=None, skip_mods=None)\n\nMapping from symbol names to URLs with docs\nSymbol names are taken from libraries registered using the ‘nbdev’ entry point. By default, all libraries with this entry point are searched, but full symbol names (including module prefix) are required.\n\nc = NbdevLookup()\nassert c['nbdev.doclinks.DocLinks'].startswith('http')\nassert c['numpy.array'].startswith('http')\nassert c['DocLinks'].startswith('http')\nassert not c['array']\n\nPass strip_libs to list libraries which should be available without requiring a module prefix.\n\nc = NbdevLookup(strip_libs=['nbdev', 'nbdev_numpy'])\nassert c['array'].startswith('http')\nassert c['DocLinks'].startswith('http')\n\nnbdev itself includes nbdev_lookup, an instantiated NbdevLookup with strip_libs=nbdev.\n\n_nbdev_lookup = NbdevLookup()\nassert _nbdev_lookup['DocLinks'].startswith('http')\nassert _nbdev_lookup['numpy.array'].startswith('http')\nassert not _nbdev_lookup['array']"
  },
  {
    "objectID": "doclinks.html#backticks",
    "href": "doclinks.html#backticks",
    "title": "doclinks",
    "section": "Backticks",
    "text": "Backticks\n\n\nNbdevLookup.linkify\n\n NbdevLookup.linkify (md)\n\n\n\n\nNbdevLookup.link_line\n\n NbdevLookup.link_line (l)\n\n\nmd = \"\"\"This is a link to `numpy.array` and to `get_config` but not a link to `foobar`.\nAnd not a link to <code>dict2nb</code>.\n\n    This is not a link to `get_config`\nThis isn’t a link to get_config either\n\n\n\nc = NbdevLookup('nbdev')\nMarkdown(c.linkify(md))\n\nThis is a link to [numpy.array](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array) and to [get_config](https://nbdev.fast.ai/read.html#get_config) but not a link to foobar. And not a link to dict2nb.\nThis is not a link to [`get_config`](https://nbdev.fast.ai/read.html#get_config)\nThis isn't a link to [`get_config`](https://nbdev.fast.ai/read.html#get_config) either\n\n\n\nPath('../nbdev/export.py').unlink(missing_ok=True)\nnbdev_export()\n\ng = exec_new('import nbdev.export')\nassert hasattr(g['nbdev'].export, 'nb_export')\nfrom nbdev._modidx import d\nassert d['syms']['nbdev.doclinks']['nbdev.doclinks.DocLinks'].startswith('http')"
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "NB: This is nbdev v2, a major upgrade of nbdev. Whilst the differences to nbdev1 aren’t huge, it does require some changes. The old version docs are at nbdev1.fast.ai. You can use version-pinning in settings.ini (i.e 'nbdev<2') to stop nbdev from upgrading. To upgrade, follow the migration tutorial.\nnbdev is a system for exploratory programming. Simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free!\nnbdev makes debugging and refactoring your code much easier than in traditional programming environments since you always have live objects at your fingertips. nbdev also promotes software engineering best practices because tests and documentation are first class."
  },
  {
    "objectID": "getting_started.html#install",
    "href": "getting_started.html#install",
    "title": "Getting started",
    "section": "Install",
    "text": "Install\nnbdev works on macOS, Linux, and most Unix-style operating systems. It works on Windows under WSL, but not under cmd or Powershell.\nYou can install nbdev with pip:\npip install nbdev\n… or with conda (or mamba):\nconda install -c fastai nbdev\nNote that nbdev must be installed into the same Python environment that you use for both Jupyter and your project."
  },
  {
    "objectID": "getting_started.html#how-to-use-nbdev",
    "href": "getting_started.html#how-to-use-nbdev",
    "title": "Getting started",
    "section": "How to use nbdev",
    "text": "How to use nbdev\nThe best way to learn to use nbdev is to complete one of these tutorials (we suggest replicating each step to solidify your understanding):\n\nWritten tutorial\n\nVideo step-by-step walkthru (to view full screen, click the little square in the bottom right of the video; to view in a separate Youtube window, click the Youtube logo):\n\n\n\n\n(There’s an alternate version of the walkthru available with the coding sections sped up using the unsilence python library – it’s 27 minutes faster, but it’s be harder to follow along with.)\nYou can run nbdev_help from the terminal to see the full list of available commands:\n\n!nbdev_help\n\nnbdev_bump_version              Increment version in settings.ini by one\nnbdev_changelog                 Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean                     Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda                     Create and upload a conda package\nnbdev_create_config             Create a config file\nnbdev_deploy                    Deploy docs to GitHub Pages\nnbdev_docs                      Generate docs\nnbdev_export                    Export notebooks in `path` to Python modules\nnbdev_filter                    A notebook filter for Quarto\nnbdev_fix                       Create working notebook from conflicted notebook `nbname`\nnbdev_ghp_deploy                Deploy docs in `doc_path` from settings.ini to GitHub Pages\nnbdev_help                      Show help for all console scripts\nnbdev_install                   Install Quarto and the current library\nnbdev_install_hooks             Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto            Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge                     Git merge driver for notebooks\nnbdev_migrate                   Convert all directives and callouts in `fname` from v1 to v2\nnbdev_new                       Create a new project from the current git repo\nnbdev_prepare                   Export, test, and clean notebooks\nnbdev_preview                   Start a local docs webserver\nnbdev_pypi                      Create and upload Python package to PyPI\nnbdev_quarto                    Create Quarto docs and README.md\nnbdev_readme                    Render README.md from index.ipynb\nnbdev_release                   Release both conda and PyPI packages\nnbdev_release_gh                Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git               Tag and create a release in GitHub for the current version\nnbdev_sidebar                   Create sidebar.yml\nnbdev_test                      Test in parallel notebooks matching `fname`, passing along `flags`\nnbdev_trust                     Trust notebooks matching `fname`\nnbdev_update                    Propagate change in modules matching `fname` to notebooks that created them"
  },
  {
    "objectID": "getting_started.html#faq",
    "href": "getting_started.html#faq",
    "title": "Getting started",
    "section": "FAQ",
    "text": "FAQ\n\nQ: Someone told me not to use notebooks for “serious” software development!\nWatch this video. Don’t worry, we still get this too, despite having used nbdev for a wide range of “very serious” software projects over the last three years, including deep learning libraries, API clients, Python language extensions, terminal user interfaces, and more!"
  },
  {
    "objectID": "getting_started.html#nbdev-in-the-wild",
    "href": "getting_started.html#nbdev-in-the-wild",
    "title": "Getting started",
    "section": "nbdev in the wild",
    "text": "nbdev in the wild\n\nfastai ecosystem\nnbdev has been used to build innovative software in the fastai ecosystem, including the fastai deep learning library which implements a unique layered API and callback system, and fastcore, which supercharges Python leveraging its dynamic nature. Furthermore, nbdev allows a very small number of developers to maintain and grow a large ecosystem of software engineering, data science, machine learning, and devops tools."
  },
  {
    "objectID": "getting_started.html#contributing",
    "href": "getting_started.html#contributing",
    "title": "Getting started",
    "section": "Contributing",
    "text": "Contributing\nIf you want to contribute to nbdev, be sure to review the contributions guidelines. This project adheres to fastai’s code of conduct. By participating, you are expected to uphold this code. In general, we strive to abide by generally accepted best practices in open-source software development.\nMake sure you have nbdev’s git hooks installed by running nbdev_install_hooks in the cloned repository."
  },
  {
    "objectID": "getting_started.html#copyright",
    "href": "getting_started.html#copyright",
    "title": "Getting started",
    "section": "Copyright",
    "text": "Copyright\nCopyright © 2019 onward fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the “License”); you may not use this project’s files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository."
  },
  {
    "objectID": "git_friendly_jupyter.html",
    "href": "git_friendly_jupyter.html",
    "title": "Git-friendly Jupyter",
    "section": "",
    "text": "Version control is essential to developing software, yet Jupyer notebooks don’t work with version control by default. nbdev solves this problem! It provides a set of hooks which enable git-friendly Jupyter notebooks in any git repo, including those that don’t use the broader nbdev system.\nTo get started, install nbdev:\nthen install hooks:\nThat’s it! Read on if you’re stuck or if you’d like to learn more about nbdev hooks and how to customise them."
  },
  {
    "objectID": "git_friendly_jupyter.html#quickstart-install-nbdev-hooks-for-a-repo",
    "href": "git_friendly_jupyter.html#quickstart-install-nbdev-hooks-for-a-repo",
    "title": "Git-friendly Jupyter",
    "section": "Quickstart: Install nbdev hooks for a repo",
    "text": "Quickstart: Install nbdev hooks for a repo\nTo start with, change directory to your current project and double-check. Don’t worry about the strange path, that’s because we’re using a temporary directory for this tutorial:\n\n!pwd\n\n/private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmp15d4zvbi/repo\n\n\nInstall nbdev:\n\n!pip install -Uqq nbdev\n\nInstall nbdev hooks:\n\n!nbdev_install_hooks\n\nNot in a git repository, git hooks cannot be installed.\n\n\nYou’ll see the above error if you’re not in a git repo. If so, initialise a git repository:\n\n!git init\n\nInitialized empty Git repository in /private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmp15d4zvbi/repo/.git/\n\n\nThen try installing nbdev hooks again:\n\n!nbdev_install_hooks\n\nHooks are installed.\n\n\nIf you already have a pre-save hook set in your Jupyter config file we won’t be able to safely install a new one automatically. Instead, you’ll encounter an error and will need to follow its instructions for a manual installation.\nJupyter hooks will now be installed in your user’s Jupyter config directory, and will work for all repos by default. Git hooks will only be installed in the current repo; you will need to rerun nbdev_install_hooks for each of your git repos. See Configuring nbdev hooks if you’d like to customise hook behaviour, for example, to opt out of hooks in certain repos."
  },
  {
    "objectID": "git_friendly_jupyter.html#what-are-nbdev-hooks",
    "href": "git_friendly_jupyter.html#what-are-nbdev-hooks",
    "title": "Git-friendly Jupyter",
    "section": "What are nbdev hooks?",
    "text": "What are nbdev hooks?\nnbdev provides three hooks to ease Jupyter-git integration.\n\nnbdev_merge on merging notebooks with git\nOne of the biggest complaints when working with Jupyter is that merge conflicts break notebooks. This is particularly problematic in projects with many collaborators.\n\n\n\nJupyter notebook shows the above error when opening a notebook with merge conflicts.\n\n\nOftentimes these conflicts are on metadata like cell execution counts that we don’t really care about. nbdev comes with a custom git merge driver that automatically fixes conflicting outputs and metadata, and that leaves remaining conflicts in a state that still works with Jupyter. It works in all git commands that use merge under the hood, including merge, pull, rebase, and stash.\nHere’s what the conflict looks like in Jupyter with nbdev’s merge driver:\n\n\n\n\n\n\n\nnbdev_clean on saving notebooks in Jupyter\nJupyter notebooks store a variety of metadata (including execution counts and notebook extension info) that aren’t conducive to collaborative version control systems like git. These pollute diffs in pull requests and git histories (which can make debugging harder), and tend to cause merge conflicts. For example:\n  {\n   \"cell_type\": \"code\",\n-  \"execution_count\": 1,\n+  \"execution_count\": 2,\n   \"metadata\": {\n     \"hide_input\": false\n  }\nPython’s default repr is another example, since it includes a memory address which we usually aren’t interested in:\n-<matplotlib.axes._subplots.AxesSubplot at 0x7fbc11508950>\n+<matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90>\nnbdev install a Jupyter hook which runs nbdev_clean to automatically clean unwanted metadata and outputs from your notebooks, including ids from default Python reprs! With nbdev hooks, the examples above would become:\n{\n  \"cell_type\": \"code\",\n  \"execution_count\": null,\n  \"metadata\": {}\n}\nand\n<matplotlib.axes._subplots.AxesSubplot>\n\n\nnbdev_trust after merging notebooks with git\nA side-effect of Jupyter’s security model is that widgets don’t work in collaborative repos, unless you manually “trust” notebooks after each git pull. There is a good reason behind this: since Jupyter notebooks contain HTML and JavaScript, the trust system avoids running malicious code when you open a notebook and don’t explicitly run any cells. See the official documentation for more.\nManually trusting notebooks each time is a pain. A more natural workflow would be trust a repo once-off, and all notebooks and changes thereafter. nbdev includes a git post-merge hook which runs nbdev_trust in your repo to do exactly this."
  },
  {
    "objectID": "git_friendly_jupyter.html#configuring-nbdev-hooks",
    "href": "git_friendly_jupyter.html#configuring-nbdev-hooks",
    "title": "Git-friendly Jupyter",
    "section": "Configuring nbdev hooks",
    "text": "Configuring nbdev hooks\nThe most up-to-date reference of nbdev’s settings is in the nbdev_create_config docs. In addition, this section will guide you through a few common configurations.\nControl whether Jupyter hooks are run:\n\nGlobally enable Jupyter hooks: set jupyter_hooks = True in user settings\nGlobally disable Jupyter hooks: set jupyter_hooks = False in user settings (at ~/.config/nbdev/settings.ini)\nEnable Jupyter hooks only for selected repos: set jupyter_hooks = False in user settings and jupyter_hooks = True in selected repo settings\n\nCustomise notebook cleaning with the following settings:\n\nClean all outputs and metadata: clear_all\nPreserve certain metadata by key: allowed_metadata_keys and allowed_cell_metadata_keys\nClean ids from default Python reprs: clean_ids\n\nAll of the above can be customised per-user and per-repo.\nControl whether git hooks are run:\nSince git hooks are installed per-repo they’ll only run in repos where you manually nbdev_install_hooks. If you change your mind later, you can uninstall git hooks by following the instructions in the .gitconfig file created in your repo."
  },
  {
    "objectID": "sync.html",
    "href": "sync.html",
    "title": "sync",
    "section": "",
    "text": "absolute_import\n\n absolute_import (name, fname, level)\n\nUnwarps a relative import in name according to fname\n\ntest_eq(absolute_import('xyz', 'nbdev', 0), 'xyz')\ntest_eq(absolute_import('', 'nbdev', 1), 'nbdev')\ntest_eq(absolute_import('core', 'nbdev', 1), 'nbdev.core')\ntest_eq(absolute_import('core', 'nbdev/vision', 2), 'nbdev.core')\ntest_eq(absolute_import('transform', 'nbdev/vision', 1), 'nbdev.vision.transform')\ntest_eq(absolute_import('notebook.core', 'nbdev/data', 2), 'nbdev.notebook.core')\n\n\n\n\nnbdev_update\n\n nbdev_update (fname:str)\n\nPropagate change in modules matching fname to notebooks that created them\n\n\n\n\nType\nDetails\n\n\n\n\nfname\nstr\nA Python file name to update"
  },
  {
    "objectID": "processors.html",
    "href": "processors.html",
    "title": "processors",
    "section": "",
    "text": "On this page we’ll be using this private helper to process a notebook and return the results, to simplify testing:\n\ndef _run_procs(procs=None, preprocs=None, postprocs=None, return_nb=False, path=_test_file):\n    nbp = NBProcessor(path, procs, preprocs=preprocs, postprocs=postprocs)\n    nbp.process()\n    if return_nb: return nbp.nb\n    return '\\n'.join([str(cell) for cell in nbp.nb.cells])"
  },
  {
    "objectID": "processors.html#notebook-preprocessors",
    "href": "processors.html#notebook-preprocessors",
    "title": "processors",
    "section": "Notebook preprocessors",
    "text": "Notebook preprocessors\n\n\nyml2dict\n\n yml2dict (s:str, rm_fence=True)\n\nconvert a string that is in a yaml format to a dict\n\n\n\nis_frontmatter\n\n is_frontmatter (nb)\n\nList of raw cells in nb that contain frontmatter\n\n\n\npopulate_language\n\n populate_language (nb)\n\nInsert cell language indicator based on notebook metadata. You should to use this before lang_identify\n\n\n\ninsert_warning\n\n insert_warning (nb)\n\nInsert Autogenerated Warning Into Notebook after the first cell.\nThis preprocessor inserts a warning in the markdown destination that the file is autogenerated. This warning is inserted in the second cell so we do not interfere with front matter.\n\nres = _run_procs(preprocs=[insert_warning])\nassert \"<!-- WARNING: THIS FILE WAS AUTOGENERATED!\" in res\n\n\nL('foo', None, 'a').filter(lambda x:x == 1)\n_tstre = re.compile('a')\n\n\n\n\nadd_show_docs\n\n add_show_docs (nb)\n\nAdd show_doc cells after exported cells, unless they are already documented\n\n\n\ncell_lang\n\n cell_lang (cell)\n\n\nres = _run_procs(preprocs=[populate_language, add_show_docs])\nassert \"show_doc(some_func)'\" in res\nassert \"show_doc(and_another)'\" in res\nassert \"show_doc(another_func)'\" not in res\n\n\n\n\nyaml_str\n\n yaml_str (s:str)\n\nCreate a valid YAML string from s\n\n\n\nnb_fmdict\n\n nb_fmdict (nb, remove=True)\n\nInfer the front matter from a notebook’s markdown formatting\n\n_testnb = read_nb('../tests/docs_test.ipynb')\n_res = nb_fmdict(_testnb)\ntest_eq(_res, dict(key1='value1', key2='value2', categories=['c1', 'c2'], title='a title', description='A description'))\n\n\n\n\nfilter_fm\n\n filter_fm (fmdict:dict)\n\nFilter front matter\n\n\n\nconstruct_fm\n\n construct_fm (fmdict:dict)\n\nConstruct front matter from a dictionary\n\n_testdict = nb_fmdict(read_nb('../tests/docs_test.ipynb'))\n_res = construct_fm(filter_fm(_testdict))\ntest_eq(len(_res.splitlines()), 8)\nprint(_res)\n\n---\ncategories:\n- c1\n- c2\ndescription: A description\ntitle: a title\n\n---\n\n\n\n\n\ninsert_frontmatter\n\n insert_frontmatter (nb, fm_dict:dict)\n\nAdd frontmatter into notebook based on filter_keys that exist in fmdict.\n\n\n\ninfer_frontmatter\n\n infer_frontmatter (nb)\n\nInsert front matter if it doesn’t exist automatically from nbdev styled markdown.\n\n_raw_res = _run_procs()\n_res = _run_procs(preprocs=infer_frontmatter)\nassert '# a title' in _raw_res and '# a title' not in _res\nassert r'description: A description\\n' in _res\nassert r'categories:\\n- c1\\n- c2\\n' in _res\nassert r'output-file: foobar.html\\n' in _res\n\nIf you already have front matter in a raw cell that will take precedence over markdown style frontmatter. For example, this notebook has the the following front matter defined in a raw cell:\n\n\n---\ntitle: fastcore my favorite python library\n---\n\n\n…as well as a Markdown front matter shortcuts like this:\n\n\n# \"fastcore: An Underrated Python Library\"\n\n> A unique python library that extends the python programming language and provides utilities that enhance productivity.\n- author: \"<a href='https://twitter.com/HamelHusain'>Hamel Husain</a>\"\n- toc: false\n- image: images/copied_from_nb/fastcore_imgs/td.png\n- comments: true\n- search_exclude: true\n- hide: true\n- categories: [fastcore, fastai]\n- permalink: /fastcore/\n- badges: true\n\n\nWhen this notebook is processed, the front matter looks like this, as you can see the title from the raw front matter takes precedence:\n\n_res = _run_procs(preprocs=infer_frontmatter, path='../tests/2020-09-01-fastcore.ipynb', return_nb=True)\nprint(_res['cells'][0].source)\n\n---\nauthor: <a href='https://twitter.com/HamelHusain'>Hamel Husain</a>\ncategories:\n- fastcore\n- fastai\ncomments: true\ndescription: A unique python library that extends the python programming language\n  and provides utilities that enhance productivity.\nimage: fastcore_imgs/td.png\ntitle: fastcore my favorite python library\n\n---\n\n\nAdditionally, as shown above, front matter from fastpages is automatically aliased to conform to Quarto including modifying the image path, which minimizes burden on folks migrating from fastpages."
  },
  {
    "objectID": "processors.html#cell-processors",
    "href": "processors.html#cell-processors",
    "title": "processors",
    "section": "Cell processors",
    "text": "Cell processors\n\n\nnbflags_\n\n nbflags_ (nbp, cell, *args)\n\nStore flags marked with nbflags\n\nnbp = NBProcessor('../tests/01_everything.ipynb', nbflags_)\nnbp.process()\ntest_eq(nbp.nb._nbflags, ('foobar',))\n\n\n\n\nadd_links\n\n add_links (cell)\n\nAdd links to markdown cells\n\nres = _run_procs(add_links)\nassert \"[`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array)\" in res\nassert \"[`ModuleMaker`](https://nbdev.fast.ai/maker.html#modulemaker) but not a link to `foobar`.\" in res\nassert \"A link in a docstring: [`ModuleMaker`](https://nbdev.fast.ai/maker.html#modulemaker).\" in res\nassert \"And not a link to <code>dict2nb</code>.\" in res\n\nGets rid of colors that are streamed from standard out, which can interfere with static site generators:\n\n\n\nstrip_ansi\n\n strip_ansi (cell)\n\nStrip Ansi Characters.\n\nres = _run_procs(strip_ansi)\nassert not _re_ansi_escape.findall(res)\n\n\n\n\nstrip_hidden_metadata\n\n strip_hidden_metadata (cell)\n\nStrips “hidden” metadata property from code cells so it doesn’t interfere with docs rendering\n\n\n\nhide_\n\n hide_ (nbp, cell)\n\nHide cell from output\n\nres = _run_procs(hide_)\nassert 'you will not be able to see this cell at all either' not in res\n\n\n\n\nhide_line\n\n hide_line (cell)\n\nHide lines of code in code cells with the directive hide_line at the end of a line of code\n\nres = _run_procs(hide_line)\nassert r\"def show():\\n    a = 2\\n    b = 3\" not in res\nassert r\"def show():\\n    a = 2\"                in res\n\n\n\n\nfilter_stream_\n\n filter_stream_ (nbp, cell, *words)\n\nRemove output lines containing any of words in cell stream output\n\nres = _run_procs(filter_stream_)\nexp=r\"'A line\\n', 'Another line.\\n'\"\nassert exp in res\n\n\n\n\nclean_magics\n\n clean_magics (cell)\n\nA preprocessor to remove cell magic commands\n\nres = _run_procs(clean_magics)\nassert \"%%\" not in res\n\n\n\n\nlang_identify\n\n lang_identify (cell)\n\nA preprocessor to identify bash/js/etc cells and mark them appropriately\nWhen we issue a shell command in a notebook with !, we need to change the code-fence from python to bash and remove the !:\n\nres = _run_procs(lang_identify)\nassert \"'language': 'bash'\" in res\n\n\n\n\nrm_header_dash\n\n rm_header_dash (cell)\n\nRemove headings that end with a dash -\n\nres = _run_procs(rm_header_dash)\nassert 'some words' in res\nassert 'A heading to Hide' not in res\nassert 'Yet another heading to hide' not in res\n\n\n\n\nrm_export\n\n rm_export (cell)\n\nRemove cells that are exported or hidden\n\nres = _run_procs(rm_export)\nassert 'dontshow' not in res\n\n\n\n\nclean_show_doc\n\n clean_show_doc (cell)\n\nRemove ShowDoc input cells\n\n\n\nexec_show_docs\n\n exec_show_docs (nb)\n\nExecute cells needed for show_docs output, including exported cells and imports\n\nres = _run_procs([exec_show_docs])\nassert res"
  },
  {
    "objectID": "processors.html#notebook-postprocessors",
    "href": "processors.html#notebook-postprocessors",
    "title": "processors",
    "section": "Notebook postprocessors",
    "text": "Notebook postprocessors\nThere are no notebook postprocessors yet."
  },
  {
    "objectID": "release.html",
    "href": "release.html",
    "title": "release",
    "section": "",
    "text": "nbdev.release provides 3 commands that you can run from your shell:\n\nnbdev_changelog: creates a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_release_git: tags and creates a release in GitHub for the current version\nnbdev_release_gh: calls nbdev_changelog, lets you edit the result, then pushes to git and calls nbdev_release_git\n\nHere’s a brief demonstration of how to use the tools in nbdev.release. This demo first creates an issue using the gh command line tool, and then closes it using git; you can also use GitHub’s web interface for both of these tasks. (Note that this functionality used to be in a project called fastrelease, so in the video the command line tools have different names, starting with fastrelease_ instead of nbdev_).\n\n\n\nFirst, create a settings.ini file with the following contents (replacing the values as described below):\n[DEFAULT]\nlib_name = fastrelease\nuser = fastai\nversion = 0.0.1\nSet lib_name to the name of GitHub repo, user to the owner of that repo, and version to the version number of your library. (Note that if you use nbdev then you’ll already have this information, so you don’t need to do anything further to set it up.)\nYou’ll need to get a GitHub personal access token if you haven’t already. To do so, click here and enter “fastrelease” in the “Note” section, and click the repo checkbox.\nThen click “Generate Token” at the bottom of the screen, and copy the token (the long string of letters and numbers shown). You can easily do that by clicking the little clipboard icon next to the token.\n\nPaste that token into a file called token into the root of your repo. You can run the following in your terminal (cd to the root of your repo first) to create that file:\necho XXX > token\nReplace XXX above with the token you copied. Also, ensure that this file isn’t added to git, by running this in your terminal:\necho token >> .gitignore\n\n\n\nNow you’re ready to create your release notes. These are created in a file called CHANGELOG.md. Here’s an example of what it creates: nbdev CHANGELOG.\nAll issues with the label bug, enhancement, or breaking that have been closed in your repo since your last release will be added to the top of this file. If you haven’t made any releases before, then all issues with those labels will be included.\nTherefore, before you create or update CHANGELOG.md, go to your GitHub issues page, remove is:open from the filter, and label any issues you want included with one of the labels above. When you’ve done that, you can create or update your release notes by running in your terminal:\nnbdev_changelog\nThe titles and bodies of each issue will be added. Open CHANGELOG.md in your editor and make any edits that you want, and then commit the file to your repo (remember to git add it!)\n\n\n\nYou should now tag a release. This will create a tag in GitHub with your current version number in settings.ini, and will then make it into a release, using your latest release notes as the description of the release:\nnbdev_release_git\nAfter you run this, be sure to increment your version number in settings.ini. You can either edit it manually, or if you use nbdev it can be done for you by running:\nnbdev_bump_version\n\n\n\nTo complete both of the steps above, run:\nnbdev_release_gh\nSee the screencast above for a demonstration of this."
  },
  {
    "objectID": "release.html#python-api",
    "href": "release.html#python-api",
    "title": "release",
    "section": "Python API",
    "text": "Python API\n\n\nRelease\n\n Release (owner=None, repo=None, token=None, **groups)\n\nCreate CHANGELOG.md from GitHub issues\nTo create a markdown changelog, first create a Release object, optionally passing a mapping from GitHub labels to markdown titles. Put your github token in a file named token at the root of your repo. Release attempts to fetch values for arguments from the following locations if not supplied:\n\nowner: fetched from the field user in settings.ini. This is the owner name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastai.\nrepo: fetched from the field lib_name in settings.ini. This is the name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastcore.\ntoken: fetched from a file named token at the root of your repo. Creating a token is discussed in the setup section.\ngroups: (optional) fetched from the field label_groups in settings.ini, which is a JSON string. This is a mapping from label names to titles in your release notes. If not specified, this defaults to:\n\n{\"breaking\": \"Breaking Changes\", \"enhancement\":\"New Features\", \"bug\":\"Bugs Squashed\"}\n\n\nRelease.changelog\n\n Release.changelog (debug=False)\n\nCreate the CHANGELOG.md file, or return the proposed text if debug is True\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndebug\nbool\nFalse\nJust print the latest changes, instead of updating file\n\n\n\n\nrel = Release()\nprint(rel.changelog(debug=True))\n\n\n## 2.1.1\n\n\n### Bugs Squashed\n\n- fix `nbdev_test` with no `--fname` in non-nbdev repos ([#730](https://github.com/fastai/nbdev/pull/730)), thanks to [@seeM](https://github.com/seeM)\n\n- Auto-generated showdoc headers not in ToC ([#703](https://github.com/fastai/nbdev/issues/703))\n  - Should have been fixed in Quarto here:\n\nhttps://github.com/quarto-dev/quarto-cli/commit/dbb9de99a1ad959d1d6e064654002a8247138289\n\nCheck whether `#| output: asis` fixes it.\n\n\n\n\n\n\nRelease.release\n\n Release.release ()\n\nTag and create a release in GitHub for the current version\nThis uses the version information from your settings.ini.\n\n\n\nRelease.latest_notes\n\n Release.latest_notes ()\n\nLatest CHANGELOG entry\nAll relevant pull requests and issues are fetched from the GitHub API, and are categorized according to a user-supplied mapping from labels to markdown headings."
  },
  {
    "objectID": "release.html#cli-functions",
    "href": "release.html#cli-functions",
    "title": "release",
    "section": "CLI functions",
    "text": "CLI functions\n\n\nchangelog\n\n changelog (debug:<functionstore_true>=False, repo:str=None)\n\nCreate a CHANGELOG.md file from closed and labeled GitHub issues\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndebug\nstore_true\nFalse\nPrint info to be added to CHANGELOG, instead of updating file\n\n\nrepo\nstr\nNone\nrepo to use instead of lib_name from settings.ini\n\n\n\n\n\n\nrelease_git\n\n release_git (token:str=None)\n\nTag and create a release in GitHub for the current version\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntoken\nstr\nNone\nOptional GitHub token (otherwise token file is used)\n\n\n\n\n\n\nrelease_gh\n\n release_gh (token:str=None)\n\nCalls nbdev_changelog, lets you edit the result, then pushes to git and calls nbdev_release_git\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntoken\nstr\nNone\nOptional GitHub token (otherwise token file is used)"
  },
  {
    "objectID": "showdoc.html",
    "href": "showdoc.html",
    "title": "showdoc",
    "section": "",
    "text": "Render nicely formatted tables that shows docments for any function or method.\n\n\n\n\n DocmentTbl (obj, verbose=True, returns=True)\n\nCompute the docment table string\nDocmentTbl can render a markdown table showing docments if appropriate. This is an example of how a docments table will render for a function:\n\ndef _f(a,      # description of param a \n       b=True, # description of param b\n       c:str=None\n       ) -> int: ...\n\n_dm = DocmentTbl(_f)\n_dm\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\nReturns\nint\n\n\n\n\n\n\n\nIf one column in the table has no information, for example because there are no default values, that column will not be shown. In the below example, the Default column, will not be shown. Additionally, if the return of the function is not annotated the Returns row will not be rendered:\n\ndef _f(a, \n        b, #param b\n        c  #param c\n       ): ...\n\n_dm2 = DocmentTbl(_f)\n_dm2\n\n\n\n\n\nDetails\n\n\n\n\na\n\n\n\nb\nparam b\n\n\nc\nparam c\n\n\n\n\n\nDocmentTbl also works on classes. By default, the __init__ will be rendered:\n\nclass _Test:\n    def __init__(self, \n                 a,      # description of param a \n                 b=True, # description of param b\n                 c:str=None):\n        ...\n        \n    def foo(self, \n            c:int,      # description of param c\n            d=True, # description of param d\n           ):\n        ...\n\n\nDocmentTbl(_Test)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\n\n\n\nYou can also pass a method to be rendered as well:\n\nDocmentTbl(_Test.foo)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nc\nint\n\ndescription of param c\n\n\nd\nbool\nTrue\ndescription of param d"
  },
  {
    "objectID": "showdoc.html#documentation-for-an-object",
    "href": "showdoc.html#documentation-for-an-object",
    "title": "showdoc",
    "section": "Documentation For An Object",
    "text": "Documentation For An Object\nRender the signature as well as the docments to show complete documentation for an object.\n\n\nShowDocRenderer\n\n ShowDocRenderer (sym, name:str|None=None, title_level:int|None=None)\n\nShow documentation for sym\n\n\n\nBasicMarkdownRenderer\n\n BasicMarkdownRenderer (sym, name:str|None=None,\n                        title_level:int|None=None)\n\nShow documentation for sym\n\n\nshow_doc\n\n show_doc (sym, renderer=None, name:str|None=None,\n           title_level:int|None=None)\n\nYou can use show_doc to document apis of functions, classes or methods:\n\n\n\nf\n\n f (x:int=1)\n\nfunc docstring\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nint\n1\nthe parameter x\n\n\nReturns\nNone\n\nthis function doesn’t return anything\n\n\n\n\n\n\ndoc\n\n doc (elt, show_all_docments:bool=False)\n\nShow show_doc info along with link to docs\n\ndoc(NbdevLookup)\n\n\n\nNbdevLookup\n\n NbdevLookup (strip_libs=None, incl_libs=None, skip_mods=None)\n\nMapping from symbol names to URLs with docs\nShow in docs\n\n\n\n\n\n\nNumpy Docstrings\nif you have numpy docstrings instead of docments, show_doc will attempt to parse and render those just like docments:\n\n\nf\n\n f (x=1)\n\nfunc docstring in the numpy style.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nint\n1\nthe parameter x\n\n\nReturns\nNone\n\nthis function doesn’t return anything\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNumpy docstring formatting is very strict. If your docstrings do not strictly adhere to the numpy format, it will not be parsed properly and information about parameters and return values may not properly be rendered in the table below the signature. Where possible, we recommend using docments to annonate your function instead."
  },
  {
    "objectID": "showdoc.html#show_doc-on-classes",
    "href": "showdoc.html#show_doc-on-classes",
    "title": "showdoc",
    "section": "show_doc on Classes",
    "text": "show_doc on Classes\nshow_doc works on Classes, too including when you use @patch:\n\n\nFoo\n\n Foo (d:str, e:int)\n\nThis is the docstring for the init method\nYou can define methods for the class Foo with @patch which is convenient in allowing you to break up code for documentation in notebooks:\n\n@patch\ndef a_method(self:Foo, \n             a:list, # param a\n             b:dict,c):\n        \"This is a method\"\n        ...\n\n_res = show_doc(Foo.a_method)\n_res\n\n\n\nFoo.a_method\n\n Foo.a_method (a:list, b:dict, c)\n\nThis is a method\n\n\n\n\nType\nDetails\n\n\n\n\na\nlist\nparam a\n\n\nb\ndict\n\n\n\nc\n\n\n\n\n\n\n\n\nClass properties also work with showdoc:\n\n_res = show_doc(Foo.some_prop)\n_res\n\n\n\nFoo.some_prop\nThis is a class property.\n\n\n\n\n\n\nBasicHtmlRenderer\n\n BasicHtmlRenderer (sym, name:str|None=None, title_level:int|None=None)\n\nShow documentation for sym\n\nF\nF(x:int=1)class docstring\n\n_res = show_doc(F.class_method)\n_res\n\n\n\nF.class_method\n\n F.class_method (foo:str, bar:int)\n\nThis is a class method.\n\n\n\n\nType\nDetails\n\n\n\n\nfoo\nstr\ndocment for parameter foo\n\n\nbar\nint\n\n\n\n\n\n\n\n\n\nF.regular_method\n\n F.regular_method (baz:bool=True)\n\nThis is a regular method\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbaz\nbool\nTrue\ndocment for parameter baz\n\n\n\n\n\n\nshowdoc_nm\n\n showdoc_nm (tree)\n\nGet the fully qualified name for showdoc."
  },
  {
    "objectID": "showdoc.html#other-helpers",
    "href": "showdoc.html#other-helpers",
    "title": "showdoc",
    "section": "Other helpers",
    "text": "Other helpers\n\n\ncolab_link\n\n colab_link (path)\n\nGet a link to the notebook at path on Colab\n\ncolab_link('index')\n\nOpen index in Colab"
  }
]